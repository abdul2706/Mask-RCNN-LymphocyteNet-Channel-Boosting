{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fyp_maskrcnn_lymphocytenet_channel_boosting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6jtzw1e_0Fq"
      },
      "source": [
        "# MMDetection Setup\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2WJOfACYQMY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQLF4xFzmGC5"
      },
      "source": [
        "Clone Github Repo of MMDetection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhQbIBDfEkVK",
        "collapsed": true
      },
      "source": [
        "%cd \"/content\"\n",
        "!rm -rf \"/content/mmdetection\"\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd \"/content/mmdetection\"\n",
        "!git checkout ff38f207826859e7a89255b31978809717d4f096\n",
        "# git reset --hard [ENTER HERE THE COMMIT HASH YOU WANT]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVtk0xWCmO27"
      },
      "source": [
        "Confirm that working direction is: \"/content/mmdetection\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pADdAhDjY97"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-nK0WT3l894"
      },
      "source": [
        "Check versions of GCC and GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SZ3wpfppjyu"
      },
      "source": [
        "!nvcc -V\n",
        "!gcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKINrgNOmX1P"
      },
      "source": [
        "Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XMAeA-ojarr"
      },
      "source": [
        "!pip install mmcv-full\n",
        "!pip install -e .\n",
        "!pip install Pillow\n",
        "!pip install ml_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yykVQoExmaIO"
      },
      "source": [
        "Check versions of important libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMpu5MCUlxt3"
      },
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix5aZ6G713-W"
      },
      "source": [
        "Download pre-trained weights of mask-rcnn.\n",
        "\n",
        "More info at: https://github.com/open-mmlab/mmdetection/tree/master/configs/mask_rcnn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzEt2eJru0wJ"
      },
      "source": [
        "# !rm -rf checkpoints\n",
        "# !mkdir checkpoints\n",
        "# !wget -c http://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_2x_coco/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-0.392__segm_mAP-0.354_20200505_003907-3e542a40.pth \\\n",
        "#       -O checkpoints/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-0.392__segm_mAP-0.354_20200505_003907-3e542a40.pth\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM9fW7iSso9H"
      },
      "source": [
        "Use this to move trained-weights from one google drive to other drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1DzxWStqwus"
      },
      "source": [
        "# !mkdir '/content/drive/MyDrive/0-FYP/codes/mmdetection-stuff/work_dir_maskrcnn_lymphocytenet3_CM1/'\n",
        "# !mkdir '/content/drive/MyDrive/0-FYP/codes/mmdetection-stuff/work_dir_maskrcnn_lymphocytenet3_CM1/setting9/'\n",
        "# !gdown --id '1mGNPIh4DE2yaCiVNbwfkDiq8vMN1UuDG' -O \"/content/drive/MyDrive/0-FYP/codes/mmdetection-stuff/work_dir_maskrcnn_lymphocytenet3_CM1/setting9/epoch_12.pth\"\n",
        "# !gdown --id '1-OYzXh4AVRPGbKxfRIgmi4cpkrkEYP5w' -O \"/content/drive/MyDrive/0-FYP/codes/mmdetection-stuff/work_dir_maskrcnn_lymphocytenet3_CM1/setting9/None.log.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY0p7JKY1sPq"
      },
      "source": [
        "Test downloaded model on demo image to check correct setup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxX67vj_vOIp"
      },
      "source": [
        "# from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
        "\n",
        "# # Choose to use a config and initialize the detector\n",
        "# config = 'configs/ms_rcnn/ms_rcnn_r50_caffe_fpn_2x_coco.py'\n",
        "# # Setup a checkpoint file to load\n",
        "# checkpoint = 'checkpoints/ms_rcnn_r50_caffe_fpn_2x_coco_bbox_mAP-0.388__segm_mAP-0.363_20200506_004738-ee87b137.pth'\n",
        "# # initialize the detector\n",
        "# model = init_detector(config, checkpoint, device='cuda:0')\n",
        "# # Use the detector to do inference\n",
        "# img = 'demo/demo.jpg'\n",
        "# result = inference_detector(model, img)\n",
        "# # Let's plot the result\n",
        "# show_result_pyplot(model, img, result, score_thr=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSxeeODDLJgg"
      },
      "source": [
        "# Train on a custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c4XLseh_rpn"
      },
      "source": [
        "## LYSTO Dataset\n",
        "\n",
        "### Dataset Info\n",
        "1. Train Dataset: 9255 images\n",
        "2. Val Dataset: 3191 images\n",
        "3. Test Dataset: 3009 images\n",
        "\n",
        "\n",
        "### Dataset Links\n",
        "\n",
        "1. train_IHC_images: https://drive.google.com/file/d/1lNZBn5WQqOJR-hbYEkVj4ecuyFGfo29N/view?usp=sharing\n",
        "2. train_DAB_images: https://drive.google.com/file/d/1-Hmt8-5mS5PZd7evMqnB4S3bBdKAhMf5/view?usp=sharing\n",
        "3. train_mask_images1: https://drive.google.com/file/d/1oIK8wOz88ynhbtT3N-WHtKqZmG5YZh6L/view?usp=sharing\n",
        "4. train_mask_images2: https://drive.google.com/file/d/14AL7-iLO6BOHsBjkmk4X7HhRuhpo5lGq/view?usp=sharing\n",
        "5. train_mask_images3: https://drive.google.com/file/d/1-B3Zs793mB7oi_z0N8tw9INVfS6Pq0RE/view?usp=sharing\n",
        "6. train_circular_masks: https://drive.google.com/file/d/1lYQVpesWlIK1jf-yGVntSbmaOliL7m1Z/view?usp=sharing\n",
        "\n",
        "\n",
        "1. val_IHC_images: https://drive.google.com/file/d/1-0rqP8l7huxXhuvjaJ4EeIj04zjCTW84/view?usp=sharing\n",
        "2. val_DAB_images: https://drive.google.com/file/d/1-DJSgpfMQQXcGNyfwZ1EfpkFUzXv56h8/view?usp=sharing\n",
        "3. val_mask_images: https://drive.google.com/file/d/1cLsZ5GB9k7ix6tRonvIFyW9GCNLFNzju/view?usp=sharing\n",
        "4. val_mask_images2: https://drive.google.com/file/d/1XuAm0OUNizUEMmbTHi4Uyk0pdyUQNNNr/view?usp=sharing\n",
        "5. val_mask_images3: https://drive.google.com/file/d/1-8aBGpvIY0Kk442sQwL0-dmhl0NOBSjC/view?usp=sharing\n",
        "6. val_circular_masks: https://drive.google.com/file/d/1FtwJKdCPT6sRSaJqzd7cm_m-U4WNHQ5u/view?usp=sharing\n",
        "\n",
        "\n",
        "1. test_IHC_images: https://drive.google.com/file/d/1-LU27w41hF7lUHnIEYtKVGHDolqP9-Wk/view?usp=sharing\n",
        "2. test_DAB_images: https://drive.google.com/file/d/1-Mp3cUjlLHsWVhcNmFnWirEqNKtIiAYa/view?usp=sharing\n",
        "3. test_mask_images: https://drive.google.com/file/d/1yywh9Z8L1fMmBV8sTPO9IYE0AZLxu5Jc/view?usp=sharing\n",
        "4. test_mask_images2: https://drive.google.com/file/d/1x3TbEwTRAiKkRjBD2xe0ZO_NYOYXeJmg/view?usp=sharing\n",
        "5. test_mask_images3: https://drive.google.com/file/d/1zGDK2arBNms6UWCbHRWUfahc0HnGX4Tn/view?usp=sharing\n",
        "6. test_circular_masks: https://drive.google.com/file/d/1vqUQbKzM6IwSXYqFFuFGYFlRjriRtUzm/view?usp=sharing\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAE31V6xyCNU"
      },
      "source": [
        "Run this cell to change current directory to \"mmdetection\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zsmQzwYLJg8"
      },
      "source": [
        "%cd \"/content/mmdetection/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTN_icbuyAcs"
      },
      "source": [
        "Confirm that working direction is: \"/content/mmdetection\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yok9LLx5LJg3"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ0hFqEdLJg9"
      },
      "source": [
        "Download Dataset Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9qWRy2xLJg-"
      },
      "source": [
        "# train dataset\n",
        "# !gdown --id \"1lNZBn5WQqOJR-hbYEkVj4ecuyFGfo29N\"         # train_IHC_images\n",
        "!gdown --id \"1-Hmt8-5mS5PZd7evMqnB4S3bBdKAhMf5\"         # train_DAB_images\n",
        "!gdown --id \"1oIK8wOz88ynhbtT3N-WHtKqZmG5YZh6L\"         # train_mask_images1\n",
        "# !gdown --id \"14AL7-iLO6BOHsBjkmk4X7HhRuhpo5lGq\"         # train_mask_images2\n",
        "# !gdown --id \"1-B3Zs793mB7oi_z0N8tw9INVfS6Pq0RE\"         # train_mask_images3\n",
        "# !gdown --id \"1lYQVpesWlIK1jf-yGVntSbmaOliL7m1Z\"         # train_circular_masks\n",
        "\n",
        "# val dataset\n",
        "# !gdown --id \"1-0rqP8l7huxXhuvjaJ4EeIj04zjCTW84\"         # val_IHC_images\n",
        "!gdown --id \"1-DJSgpfMQQXcGNyfwZ1EfpkFUzXv56h8\"         # val_DAB_images\n",
        "!gdown --id \"1cLsZ5GB9k7ix6tRonvIFyW9GCNLFNzju\"         # val_mask_images1\n",
        "# !gdown --id \"1XuAm0OUNizUEMmbTHi4Uyk0pdyUQNNNr\"         # val_mask_images2\n",
        "# !gdown --id \"1-8aBGpvIY0Kk442sQwL0-dmhl0NOBSjC\"         # val_mask_images3\n",
        "# !gdown --id \"1FtwJKdCPT6sRSaJqzd7cm_m-U4WNHQ5u\"         # val_circular_masks\n",
        "\n",
        "# test dataset\n",
        "# !gdown --id \"1-LU27w41hF7lUHnIEYtKVGHDolqP9-Wk\"         # test_IHC_images\n",
        "!gdown --id \"1-Mp3cUjlLHsWVhcNmFnWirEqNKtIiAYa\"         # test_DAB_images\n",
        "!gdown --id \"1yywh9Z8L1fMmBV8sTPO9IYE0AZLxu5Jc\"         # test_mask_images1\n",
        "# !gdown --id \"1x3TbEwTRAiKkRjBD2xe0ZO_NYOYXeJmg\"         # test_mask_images2\n",
        "# !gdown --id \"1zGDK2arBNms6UWCbHRWUfahc0HnGX4Tn\"         # test_mask_images3\n",
        "# !gdown --id \"1vqUQbKzM6IwSXYqFFuFGYFlRjriRtUzm\"         # test_circular_masks\n",
        "\n",
        "# test dataset 2\n",
        "# !gdown --id \"1fu9Erycei7CUNokUt--j4np3-6U4pluu\"         # test_IHC_images2\n",
        "# !gdown --id \"1-jWPGp2MKSx5fhE73AUy4d5zSTxuGe6w\"         # test_DAB_images2\n",
        "# !gdown --id \"1io-XBkFWoph1QpYKIry4Ge6BEyGD-zJw\"         # labels.csv (20000 rows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoEv6_08LJg_"
      },
      "source": [
        "Make directory for dataset and unzip images in that directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAHi9EceLJhA"
      },
      "source": [
        "!rm -rf \"lymphocyte_dataset\"\n",
        "!mkdir \"lymphocyte_dataset\"\n",
        "\n",
        "# !unzip \"train_IHC_images.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "!unzip \"train_DAB_images.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "!unzip \"train_mask_images1.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "# !unzip \"train_mask_images2.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "# !unzip \"train_mask_images3.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "# !unzip \"train_circular_masks.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "\n",
        "# !unzip \"val_IHC_images.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "!unzip \"val_DAB_images.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "!unzip \"val_mask_images1.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "# !unzip \"val_mask_images2.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "# !unzip \"val_mask_images3.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "# !unzip \"val_circular_masks.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "\n",
        "# !unzip \"test_IHC_images.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "!unzip \"test_DAB_images1.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "!unzip \"test_mask_images1.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "# !unzip \"test_mask_images2.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "# !unzip \"test_mask_images3.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "# !unzip \"test_circular_masks.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "\n",
        "# !unzip \"test_IHC_images2.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "# !mv \"lymphocyte_dataset/test/\" \"lymphocyte_dataset/test_IHC_images2/\"\n",
        "# !unzip \"test_DAB_images2.zip\" -d \"lymphocyte_dataset\" &> /dev/null\n",
        "# !mv \"labels.csv\" \"lymphocyte_dataset/labels.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1ZQse8uLJhC"
      },
      "source": [
        "Count number of images in each folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_4P13XQLJhD"
      },
      "source": [
        "# !ls \"lymphocyte_dataset/train_IHC_images/\" -1 | wc -l\n",
        "!ls \"lymphocyte_dataset/train_DAB_images/\" -1 | wc -l\n",
        "!ls \"lymphocyte_dataset/train_mask_images/\" -1 | wc -l\n",
        "# !ls \"lymphocyte_dataset/train_mask_images2/\" -1 | wc -l\n",
        "# !ls \"lymphocyte_dataset/train_mask_images3/\" -1 | wc -l\n",
        "# !ls \"lymphocyte_dataset/train_circular_masks/\" -1 | wc -l\n",
        "\n",
        "# !ls \"lymphocyte_dataset/val_IHC_images/\" -1 | wc -l\n",
        "!ls \"lymphocyte_dataset/val_DAB_images/\" -1 | wc -l\n",
        "!ls \"lymphocyte_dataset/val_mask_images/\" -1 | wc -l\n",
        "# !ls \"lymphocyte_dataset/val_mask_images2/\" -1 | wc -l\n",
        "# !ls \"lymphocyte_dataset/val_mask_images3/\" -1 | wc -l\n",
        "# !ls \"lymphocyte_dataset/val_circular_masks/\" -1 | wc -l\n",
        "\n",
        "# !ls \"lymphocyte_dataset/test_IHC_images/\" -1 | wc -l\n",
        "!ls \"lymphocyte_dataset/test_DAB_images1/\" -1 | wc -l\n",
        "!ls \"lymphocyte_dataset/test_mask_images/\" -1 | wc -l\n",
        "# !ls \"lymphocyte_dataset/test_mask_images2/\" -1 | wc -l\n",
        "# !ls \"lymphocyte_dataset/test_mask_images3/\" -1 | wc -l\n",
        "# !ls \"lymphocyte_dataset/test_circular_masks/\" -1 | wc -l\n",
        "\n",
        "# !ls \"lymphocyte_dataset/test_IHC_images2/\" -1 | wc -l\n",
        "# !ls \"lymphocyte_dataset/test_DAB_images2/\" -1 | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LskKA6ePLJhE"
      },
      "source": [
        "Delete the zip files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9OIMfgyLJhE"
      },
      "source": [
        "!rm -rf \"train_IHC_images.zip\"\n",
        "!rm -rf \"train_DAB_images.zip\"\n",
        "!rm -rf \"train_mask_images1.zip\"\n",
        "!rm -rf \"train_mask_images2.zip\"\n",
        "!rm -rf \"train_mask_images3.zip\"\n",
        "!rm -rf \"train_circular_masks.zip\"\n",
        "\n",
        "!rm -rf \"val_IHC_images.zip\"\n",
        "!rm -rf \"val_DAB_images.zip\"\n",
        "!rm -rf \"val_mask_images1.zip\"\n",
        "!rm -rf \"val_mask_images2.zip\"\n",
        "!rm -rf \"val_mask_images3.zip\"\n",
        "!rm -rf \"val_circular_masks.zip\"\n",
        "\n",
        "!rm -rf \"test_IHC_images.zip\"\n",
        "!rm -rf \"test_DAB_images1.zip\"\n",
        "!rm -rf \"test_mask_images1.zip\"\n",
        "!rm -rf \"test_mask_images2.zip\"\n",
        "!rm -rf \"test_mask_images3.zip\"\n",
        "!rm -rf \"test_circular_masks.zip\"\n",
        "\n",
        "!rm -rf \"test_IHC_images2.zip\"\n",
        "!rm -rf \"test_DAB_images2.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tLMEAnt21xo"
      },
      "source": [
        "# Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJk35nkZUjHx"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ml_metrics as metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from pprint import pprint\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Module, Conv2d, BatchNorm2d, MaxPool2d, AvgPool2d, AdaptiveAvgPool2d, ReLU, Sequential, Linear, Dropout, Softmax\n",
        "\n",
        "import mmcv\n",
        "from mmcv import Config, DictAction\n",
        "from mmcv.cnn import fuse_conv_bn\n",
        "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
        "from mmcv.runner import (get_dist_info, init_dist, load_checkpoint, wrap_fp16_model, build_runner)\n",
        "from mmdet.utils import get_root_logger\n",
        "\n",
        "from mmdet.datasets import build_dataloader, build_dataset, replace_ImageToTensor\n",
        "from mmdet.models import build_detector, BACKBONES, ResNet, ResNeXt, TridentResNet\n",
        "from mmdet.apis import set_random_seed, train_detector, inference_detector, init_detector, show_result_pyplot, multi_gpu_test, single_gpu_test\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'running on {device}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lHLiAOcQsfR"
      },
      "source": [
        "# Convert Annotations from Images into COCO JSON format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8sXb3aATGBi"
      },
      "source": [
        "General COCO format looks like this.\n",
        "\n",
        "```\n",
        "{\n",
        "    \"images\": [image],\n",
        "    \"annotations\": [annotation],\n",
        "    \"categories\": [category],\n",
        "}\n",
        "```\n",
        "\n",
        "where\n",
        "\n",
        "```\n",
        "image = {\n",
        "    \"id\": int,\n",
        "    \"width\": int,\n",
        "    \"height\": int,\n",
        "    \"file_name\": str\n",
        "}\n",
        "\n",
        "annotation = {\n",
        "    \"id\": int,\n",
        "    \"image_id\": int,\n",
        "    \"category_id\": int,\n",
        "    \"segmentation\": [polygon],\n",
        "    \"area\": float,\n",
        "    \"bbox\": [x, y, width, height],\n",
        "    \"iscrowd\": 0 or 1\n",
        "}\n",
        "\n",
        "polygon = [x1, y1, x2, y2, x3, y3, ..., xn, yn]\n",
        "\n",
        "category = {\n",
        "    \"id\": int,\n",
        "    \"name\": str\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rHLseB6XW_R"
      },
      "source": [
        "def get_coco_annotations(images_name, dataset_prefix, path_mask_images, path_dataset):\n",
        "    # these 3 variables represent 3 main keys in coco format\n",
        "    images = []\n",
        "    annotations = []\n",
        "    categories = [{'id': 0, 'name': 'lymphocyte'}]\n",
        "\n",
        "    # variable to track annotation id\n",
        "    obj_count = 0\n",
        "\n",
        "    for i, image_mask_name in enumerate(tqdm(images_name, total=len(images_name))):\n",
        "        # create path of mask image\n",
        "        image_mask_path = os.path.join(path_mask_images, image_mask_name)\n",
        "        # load mask image\n",
        "        image_mask = cv2.imread(image_mask_path)\n",
        "        # convert annotation image to grayscale\n",
        "        image_mask = cv2.cvtColor(image_mask, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # load image and get height and width\n",
        "        height, width = image_mask.shape\n",
        "        # insert data for ith image as required by coco format\n",
        "        images.append(dict(id=i, file_name=image_mask_name.split('.')[0] + '.jpg', height=height, width=width))\n",
        "\n",
        "        # apply threshold to image_mask\n",
        "        ret, image_threshold = cv2.threshold(image_mask, 127, 255, 0)\n",
        "        # find contours in threshold image to find pixels around cell region\n",
        "        contours, hierarchy = cv2.findContours(image_threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # loop through all contours\n",
        "        for contour in contours:\n",
        "            # one contour represents one cell in annotation image\n",
        "            contour = np.array(contour, dtype=np.float32)\n",
        "            # check to avoid very small contours (false contours)\n",
        "            if len(contour.reshape(-1)) > 4:\n",
        "                # reshape to get x-coordinates in first column and y-coordinates in second column\n",
        "                contour = contour.reshape(-1, 2)\n",
        "                # get all x-coordinates and y-coordinates\n",
        "                px = contour[:, 0]\n",
        "                py = contour[:, 1]\n",
        "                # reshape to format needed in coco i.e. [x1, y1, x2, y2, ..., xn, yn]\n",
        "                segmentation_polygon = contour.reshape(-1)\n",
        "                # these 4 values represent bounding box around cell\n",
        "                x_min, y_min, x_max, y_max = (min(px), min(py), max(px), max(py))\n",
        "                # insert data for jth annotation corrosponding to ith image\n",
        "                annotations.append(dict(\n",
        "                    image_id=i,\n",
        "                    id=obj_count,\n",
        "                    category_id=0,\n",
        "                    bbox=[int(x_min), int(y_min), int(x_max - x_min), int(y_max - y_min)],\n",
        "                    area=int((x_max - x_min) * (y_max - y_min)),\n",
        "                    segmentation=[list(segmentation_polygon)],\n",
        "                    iscrowd=0\n",
        "                ))\n",
        "                obj_count += 1\n",
        "\n",
        "    # convert final dictionary representing coco format file\n",
        "    coco_format_json = dict(images=images, annotations=annotations, categories=categories)\n",
        "    # save file as json\n",
        "    mmcv.dump(coco_format_json, os.path.join(path_dataset, dataset_prefix + '_annotations.json'), indent=4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg-SDcBFrBkl"
      },
      "source": [
        "# Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IfFMsze89NE"
      },
      "source": [
        "WORK_DIR1 = '/content/drive/MyDrive/0-FYP/codes/mmdetection-stuff/work_dir_maskrcnn_lymphocytenet3_CM1/'\n",
        "FILES_PREFIX1 = 'maskrcnn-lymphocytenet3-cm1'\n",
        "PATH_DATASET = 'lymphocyte_dataset'\n",
        "PATH_TRAIN_MASKS = os.path.join(PATH_DATASET, 'train_mask_images')\n",
        "PATH_VAL_MASKS = os.path.join(PATH_DATASET, 'val_mask_images')\n",
        "PATH_TEST_MASKS = os.path.join(PATH_DATASET, 'test_mask_images')\n",
        "\n",
        "# get file path for all weak annotation images\n",
        "train_mask_images = os.listdir(PATH_TRAIN_MASKS)[:10]\n",
        "val_mask_images = os.listdir(PATH_VAL_MASKS)[:10]\n",
        "test_mask_images = os.listdir(PATH_TEST_MASKS)[:10]\n",
        "print('train_mask_images ->', len(train_mask_images))\n",
        "print('val_mask_images ->', len(val_mask_images))\n",
        "print('test_mask_images ->', len(test_mask_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4lBS0MzIuEr"
      },
      "source": [
        "get_coco_annotations(train_mask_images, 'train', PATH_TRAIN_MASKS, PATH_DATASET)\n",
        "get_coco_annotations(val_mask_images, 'val', PATH_VAL_MASKS, PATH_DATASET)\n",
        "get_coco_annotations(test_mask_images, 'test', PATH_TEST_MASKS, PATH_DATASET)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OOmVJLo5aXV"
      },
      "source": [
        "# Define Custom Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKuhVyjB5aX7"
      },
      "source": [
        "## ResNetCBAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-tVD0Jm5aX8"
      },
      "source": [
        "### For Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F7SnaAC5aX9"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.utils.checkpoint as cp\n",
        "\n",
        "from mmcv.cnn import (build_conv_layer, build_norm_layer, build_plugin_layer, constant_init, kaiming_init)\n",
        "from mmcv.runner import load_checkpoint\n",
        "from mmdet.utils import get_root_logger\n",
        "\n",
        "from mmdet.models.builder import BACKBONES\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        self.fc1   = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2   = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
        "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
        "        out = avg_out + max_out\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "\n",
        "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
        "        padding = 3 if kernel_size == 7 else 1\n",
        "\n",
        "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        x = torch.cat([avg_out, max_out], dim=1)\n",
        "        x = self.conv1(x)\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "class BasicBlockCBAM(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_dropout=False, debug=False):\n",
        "        super(BasicBlockCBAM, self).__init__()\n",
        "\n",
        "        self.planes = planes\n",
        "\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.ca = ChannelAttention(planes)\n",
        "        self.sa = SpatialAttention()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out = self.ca(out) * out\n",
        "        out = self.sa(out) * out\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class BottleneckCBAM1(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_dropout=False, debug=False):\n",
        "        super(BottleneckCBAM1, self).__init__()\n",
        "\n",
        "        self.module_name = 'BottleneckCBAM1'\n",
        "        self.planes = planes\n",
        "        self.debug = debug\n",
        "\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout(p=0.25) if use_dropout else None\n",
        "\n",
        "        self.ca = ChannelAttention(planes * 4)\n",
        "        self.sa = SpatialAttention()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        if self.debug: print(f'[{self.module_name}][1] x.shape -> {x.shape}')\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        if self.debug: print(f'[{self.module_name}][2] out.shape -> {out.shape}')\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        if self.debug: print(f'[{self.module_name}][3] out.shape -> {out.shape}')\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        if self.debug: print(f'[{self.module_name}][4] out.shape -> {out.shape}')\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        out = self.ca(out) * out\n",
        "        if self.debug: print(f'[{self.module_name}][5] out.shape -> {out.shape}')\n",
        "        out = self.sa(out) * out\n",
        "        if self.debug: print(f'[{self.module_name}][6] out.shape -> {out.shape}')\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "            if self.debug: print(f'[{self.module_name}][7] residual.shape -> {residual.shape}')\n",
        "\n",
        "        out += residual\n",
        "        if self.debug: print(f'[{self.module_name}][8] out.shape -> {out.shape}')\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "#### added by Mam Anabia #######\n",
        "class BottleneckCBAM2(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_dropout=False, debug=False):\n",
        "        super(BottleneckCBAM2, self).__init__()\n",
        "\n",
        "        self.module_name = 'BottleneckCBAM2'\n",
        "        self.planes = planes\n",
        "        self.debug = debug\n",
        "\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.conv2a = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2a = nn.BatchNorm2d(planes)\n",
        "        self.conv2b = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False) ### additional layer added\n",
        "        self.bn2b = nn.BatchNorm2d(planes)\n",
        "        self.conv2c = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)  ###### additional layer added\n",
        "        self.bn2c = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout(p=0.25) if use_dropout else None\n",
        "\n",
        "        self.ca = ChannelAttention(planes * 4)\n",
        "        self.sa = SpatialAttention()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out) if self.dropout is not None else out\n",
        "        if self.debug: print(f'[{self.module_name}][1] out.shape -> {out.shape}')\n",
        "\n",
        "        out = self.conv2a(out) # new added\n",
        "        out = self.bn2a(out)   # new added\n",
        "        out = self.dropout(out) if self.dropout is not None else out\n",
        "        if self.debug: print(f'[{self.module_name}][1] out.shape -> {out.shape}')\n",
        "        out = self.conv2b(out)  # new added\n",
        "        out = self.bn2b(out)   # new added\n",
        "        out = self.dropout(out) if self.dropout is not None else out\n",
        "        if self.debug: print(f'[{self.module_name}][1] out.shape -> {out.shape}')\n",
        "        out = self.conv2c(out)  # new added\n",
        "        out = self.bn2c(out)   # new added\n",
        "        out = self.dropout(out) if self.dropout is not None else out\n",
        "        if self.debug: print(f'[{self.module_name}][1] out.shape -> {out.shape}')\n",
        "        out = self.relu(out)   # new added\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        out = self.dropout(out) if self.dropout is not None else out\n",
        "        if self.debug: print(f'[{self.module_name}][1] out.shape -> {out.shape}')\n",
        "\n",
        "        out = self.ca(out) * out\n",
        "        out = self.sa(out) * out\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out) if self.dropout is not None else out\n",
        "        if self.debug: print(f'[{self.module_name}][1] out.shape -> {out.shape}')\n",
        "\n",
        "        return out\n",
        "\n",
        "@BACKBONES.register_module(name='ResNetCBAM', force=True)\n",
        "class ResNetCBAM(nn.Module):\n",
        "\n",
        "    architectures = {\n",
        "        18: [BasicBlockCBAM, [2, 2, 2, 2]],\n",
        "        34: [BasicBlockCBAM, [3, 4, 6, 3]],\n",
        "        50: [BottleneckCBAM1, [3, 4, 6, 3]],\n",
        "        101: [BottleneckCBAM1, [3, 4, 23, 3]],\n",
        "        152: [BottleneckCBAM1, [3, 8, 36, 3]]\n",
        "    }\n",
        "    \n",
        "    def __init__(self, depth, debug=False):\n",
        "        super(ResNetCBAM, self).__init__()\n",
        "\n",
        "        self.module_name = 'ResNetCBAM'\n",
        "        self.depth = depth\n",
        "        self.debug = debug\n",
        "        self.inplanes = 64\n",
        "        block, layers = self.architectures[depth]\n",
        "        num_classes = 1\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, use_dropout=True)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "        for layer in [self.layer1, self.layer2]:\n",
        "            layer.training = False\n",
        "            layer.eval()\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, use_dropout=False):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = [block(self.inplanes, planes, stride, downsample, use_dropout=use_dropout, debug=False)]\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, use_dropout=use_dropout, debug=False))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.debug: print(f'[{self.module_name}][1] x.shape -> {x.shape}')\n",
        "        x = self.conv1(x)\n",
        "        if self.debug: print(f'[{self.module_name}][2] x.shape -> {x.shape}')\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        if self.debug: print(f'[{self.module_name}][5] x.shape -> {x.shape}')\n",
        "\n",
        "        level1 = self.layer1(x)\n",
        "        if self.debug: print(f'[{self.module_name}][6] level1.shape -> {level1.shape}')\n",
        "        level2 = self.layer2(level1)\n",
        "        if self.debug: print(f'[{self.module_name}][7] level2.shape -> {level2.shape}')\n",
        "        level3 = self.layer3(level2)\n",
        "        if self.debug: print(f'[{self.module_name}][8] level3.shape -> {level3.shape}')\n",
        "        level4 = self.layer4(level3)\n",
        "        if self.debug: print(f'[{self.module_name}][9] level4.shape -> {level4.shape}')\n",
        "\n",
        "        return (level1, level2, level3, level4)\n",
        "\n",
        "    def init_weights(self, pretrained=None):\n",
        "        print(f'{self.module_name} pretrained -> {pretrained}')\n",
        "        if pretrained:\n",
        "            logger = get_root_logger()\n",
        "            load_checkpoint(self, pretrained, strict=False, logger=logger)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3SEXh0S5aYI"
      },
      "source": [
        "x = torch.rand((2, 3, 224, 224))\n",
        "print(f'x.shape -> {x.shape}')\n",
        "model = ResNetCBAM(depth=50, debug=False)\n",
        "print(model)\n",
        "model.init_weights('torchvision://resnet50')\n",
        "model.eval()\n",
        "y = model(x)\n",
        "for i, level in enumerate(y):\n",
        "    print(f'level{i} -> {y[i].shape}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAXAkx1S5aYP"
      },
      "source": [
        "### For File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zapz0NS5aYQ"
      },
      "source": [
        "backbone_file_data = r\"\"\"import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.utils.checkpoint as cp\n",
        "\n",
        "from mmcv.cnn import (build_conv_layer, build_norm_layer, build_plugin_layer, constant_init, kaiming_init)\n",
        "from mmcv.runner import load_checkpoint\n",
        "from mmdet.utils import get_root_logger\n",
        "\n",
        "from mmdet.models.builder import BACKBONES\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        self.fc1   = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2   = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
        "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
        "        out = avg_out + max_out\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "\n",
        "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
        "        padding = 3 if kernel_size == 7 else 1\n",
        "\n",
        "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        x = torch.cat([avg_out, max_out], dim=1)\n",
        "        x = self.conv1(x)\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "class BasicBlockCBAM(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_dropout=False, debug=False):\n",
        "        super(BasicBlockCBAM, self).__init__()\n",
        "\n",
        "        self.planes = planes\n",
        "\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.ca = ChannelAttention(planes)\n",
        "        self.sa = SpatialAttention()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out = self.ca(out) * out\n",
        "        out = self.sa(out) * out\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class BottleneckCBAM1(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_dropout=False, debug=False):\n",
        "        super(BottleneckCBAM1, self).__init__()\n",
        "\n",
        "        self.module_name = 'BottleneckCBAM1'\n",
        "        self.planes = planes\n",
        "        self.debug = debug\n",
        "\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout(p=0.25) if use_dropout else None\n",
        "\n",
        "        self.ca = ChannelAttention(planes * 4)\n",
        "        self.sa = SpatialAttention()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        if self.debug: print(f'[{self.module_name}][1] x.shape -> {x.shape}')\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        if self.debug: print(f'[{self.module_name}][2] out.shape -> {out.shape}')\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        if self.debug: print(f'[{self.module_name}][3] out.shape -> {out.shape}')\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        if self.debug: print(f'[{self.module_name}][4] out.shape -> {out.shape}')\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        out = self.ca(out) * out\n",
        "        if self.debug: print(f'[{self.module_name}][5] out.shape -> {out.shape}')\n",
        "        out = self.sa(out) * out\n",
        "        if self.debug: print(f'[{self.module_name}][6] out.shape -> {out.shape}')\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "            if self.debug: print(f'[{self.module_name}][7] residual.shape -> {residual.shape}')\n",
        "\n",
        "        out += residual\n",
        "        if self.debug: print(f'[{self.module_name}][8] out.shape -> {out.shape}')\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "#### added by Mam Anabia #######\n",
        "class BottleneckCBAM2(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_dropout=False, debug=False):\n",
        "        super(BottleneckCBAM2, self).__init__()\n",
        "\n",
        "        self.module_name = 'BottleneckCBAM2'\n",
        "        self.planes = planes\n",
        "        self.debug = debug\n",
        "\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.conv2a = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2a = nn.BatchNorm2d(planes)\n",
        "        self.conv2b = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False) ### additional layer added\n",
        "        self.bn2b = nn.BatchNorm2d(planes)\n",
        "        self.conv2c = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)  ###### additional layer added\n",
        "        self.bn2c = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout(p=0.25) if use_dropout else None\n",
        "\n",
        "        self.ca = ChannelAttention(planes * 4)\n",
        "        self.sa = SpatialAttention()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out) if self.dropout is not None else out\n",
        "        if self.debug: print(f'[{self.module_name}][1] out.shape -> {out.shape}')\n",
        "\n",
        "        out = self.conv2a(out) # new added\n",
        "        out = self.bn2a(out)   # new added\n",
        "        out = self.dropout(out) if self.dropout is not None else out\n",
        "        if self.debug: print(f'[{self.module_name}][1] out.shape -> {out.shape}')\n",
        "        out = self.conv2b(out)  # new added\n",
        "        out = self.bn2b(out)   # new added\n",
        "        out = self.dropout(out) if self.dropout is not None else out\n",
        "        if self.debug: print(f'[{self.module_name}][1] out.shape -> {out.shape}')\n",
        "        out = self.conv2c(out)  # new added\n",
        "        out = self.bn2c(out)   # new added\n",
        "        out = self.dropout(out) if self.dropout is not None else out\n",
        "        if self.debug: print(f'[{self.module_name}][1] out.shape -> {out.shape}')\n",
        "        out = self.relu(out)   # new added\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        out = self.dropout(out) if self.dropout is not None else out\n",
        "        if self.debug: print(f'[{self.module_name}][1] out.shape -> {out.shape}')\n",
        "\n",
        "        out = self.ca(out) * out\n",
        "        out = self.sa(out) * out\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out) if self.dropout is not None else out\n",
        "        if self.debug: print(f'[{self.module_name}][1] out.shape -> {out.shape}')\n",
        "\n",
        "        return out\n",
        "\n",
        "@BACKBONES.register_module(name='ResNetCBAM', force=True)\n",
        "class ResNetCBAM(nn.Module):\n",
        "\n",
        "    architectures = {\n",
        "        18: [BasicBlockCBAM, [2, 2, 2, 2]],\n",
        "        34: [BasicBlockCBAM, [3, 4, 6, 3]],\n",
        "        50: [BottleneckCBAM1, [3, 4, 6, 3]],\n",
        "        101: [BottleneckCBAM1, [3, 4, 23, 3]],\n",
        "        152: [BottleneckCBAM1, [3, 8, 36, 3]]\n",
        "    }\n",
        "    \n",
        "    def __init__(self, depth, debug=False):\n",
        "        super(ResNetCBAM, self).__init__()\n",
        "\n",
        "        self.module_name = 'ResNetCBAM'\n",
        "        self.depth = depth\n",
        "        self.debug = debug\n",
        "        self.inplanes = 64\n",
        "        block, layers = self.architectures[depth]\n",
        "        num_classes = 1\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, use_dropout=True)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "        for layer in [self.layer1, self.layer2]:\n",
        "            layer.training = False\n",
        "            layer.eval()\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, use_dropout=False):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = [block(self.inplanes, planes, stride, downsample, use_dropout=use_dropout, debug=False)]\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, use_dropout=use_dropout, debug=False))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.debug: print(f'[{self.module_name}][1] x.shape -> {x.shape}')\n",
        "        x = self.conv1(x)\n",
        "        if self.debug: print(f'[{self.module_name}][2] x.shape -> {x.shape}')\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        if self.debug: print(f'[{self.module_name}][5] x.shape -> {x.shape}')\n",
        "\n",
        "        level1 = self.layer1(x)\n",
        "        if self.debug: print(f'[{self.module_name}][6] level1.shape -> {level1.shape}')\n",
        "        level2 = self.layer2(level1)\n",
        "        if self.debug: print(f'[{self.module_name}][7] level2.shape -> {level2.shape}')\n",
        "        level3 = self.layer3(level2)\n",
        "        if self.debug: print(f'[{self.module_name}][8] level3.shape -> {level3.shape}')\n",
        "        level4 = self.layer4(level3)\n",
        "        if self.debug: print(f'[{self.module_name}][9] level4.shape -> {level4.shape}')\n",
        "\n",
        "        return (level1, level2, level3, level4)\n",
        "\n",
        "    def init_weights(self, pretrained=None):\n",
        "        print(f'{self.module_name} pretrained -> {pretrained}')\n",
        "        if pretrained:\n",
        "            logger = get_root_logger()\n",
        "            load_checkpoint(self, pretrained, strict=False, logger=logger)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "backbone_base_path = 'mmdet/models/backbones/'\n",
        "backbone_file_name = 'resnet_cbam.py'\n",
        "backbone_file_path = os.path.join(backbone_base_path, backbone_file_name)\n",
        "with open(backbone_file_path, 'w') as backbone_file:\n",
        "    backbone_file.write(backbone_file_data)\n",
        "    print(f'<backbone_file_data> saved to \"{backbone_file_path}\"')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiYdqWXV5aYR"
      },
      "source": [
        "## LymphocyteNet3_CM1 (ResNet-50, ResNetCBAM-50)\n",
        "\n",
        "Addition/Merge at all four layers using Attention based Residual Blocks for Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Frh_l1ft5aYR"
      },
      "source": [
        "### For Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbbE4G9lvH0j"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Module, Conv2d, BatchNorm2d, MaxPool2d, AvgPool2d, AdaptiveAvgPool2d, ReLU, Sequential, Linear, Dropout, Softmax\n",
        "from mmdet.models import BACKBONES, ResNet\n",
        "from mmdet.models.backbones.resnet_cbam import ResNetCBAM\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "class ChannelAttention2(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention2, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        self.fc1   = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2   = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
        "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
        "        out = avg_out + max_out\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class SpatialAttention2(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention2, self).__init__()\n",
        "\n",
        "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
        "        padding = 3 if kernel_size == 7 else 1\n",
        "\n",
        "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        x = torch.cat([avg_out, max_out], dim=1)\n",
        "        x = self.conv1(x)\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "class BasicBlock2(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, debug=False):\n",
        "        super(BasicBlock2, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.ca = ChannelAttention2(planes)\n",
        "        self.sa = SpatialAttention2()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out = self.ca(out) * out\n",
        "        out = self.sa(out) * out\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Bottleneck2(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, debug=False):\n",
        "        super(Bottleneck2, self).__init__()\n",
        "\n",
        "        self.module_name = 'Bottleneck2'\n",
        "        self.debug = debug\n",
        "\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes // 2, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes // 2)\n",
        "        self.conv2 = nn.Conv2d(planes // 2, planes // 2, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes // 2)\n",
        "        self.conv3 = nn.Conv2d(planes // 2, planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.ca = ChannelAttention2(planes)\n",
        "        self.sa = SpatialAttention2()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        if self.debug: print(f'[{self.module_name}][1] x.shape -> {x.shape}')\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        if self.debug: print(f'[{self.module_name}][2] out.shape -> {out.shape}')\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        if self.debug: print(f'[{self.module_name}][3] out.shape -> {out.shape}')\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        if self.debug: print(f'[{self.module_name}][4] out.shape -> {out.shape}')\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        out = self.ca(out) * out\n",
        "        if self.debug: print(f'[{self.module_name}][5] out.shape -> {out.shape}')\n",
        "        out = self.sa(out) * out\n",
        "        if self.debug: print(f'[{self.module_name}][6] out.shape -> {out.shape}')\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "            if self.debug: print(f'[{self.module_name}][7] residual.shape -> {residual.shape}')\n",
        "\n",
        "        out += residual\n",
        "        if self.debug: print(f'[{self.module_name}][8] out.shape -> {out.shape}')\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "@BACKBONES.register_module(force=True, name='LymphocyteNet3_CM1')\n",
        "class LymphocyteNet3_CM1(Module):\n",
        "    def __init__(self, debug, **kwargs):\n",
        "        super(LymphocyteNet3_CM1, self).__init__()\n",
        "        \n",
        "        self.debug = debug\n",
        "        self.module_name = 'LymphocyteNet3_CM1'\n",
        "        \n",
        "        self.backbone1 = ResNet(depth=50, num_stages=4, out_indices=(0, 1, 2, 3), frozen_stages=-1, norm_cfg=dict(type='BN', requires_grad=True), norm_eval=True, style='pytorch')\n",
        "        self.backbone2 = ResNetCBAM(depth=50, debug=False)\n",
        "        # self.backbone3 = ResNeXt(depth=50, num_stages=4, out_indices=(0, 1, 2, 3), frozen_stages=1, norm_cfg=dict(type='BN', requires_grad=True), norm_eval=True, style='pytorch', groups=32, base_width=4)\n",
        "\n",
        "        self.block1 = self._make_layer(Bottleneck2, 256, 256, 2, stride=1) #1 block inppace of 2\n",
        "        self.block2 = self._make_layer(Bottleneck2, 512, 512, 2, stride=1)\n",
        "        self.block3 = self._make_layer(Bottleneck2, 1024, 1024, 2, stride=1)\n",
        "        self.block4 = self._make_layer(Bottleneck2, 2048, 2048, 2, stride=1)\n",
        "\n",
        "        self.blocks = [self.block1, self.block2, self.block3, self.block4]\n",
        "\n",
        "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "\n",
        "        layers = [block(inplanes, planes, stride, downsample, debug=False)]\n",
        "        # inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(planes, planes, debug=False))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.debug: print(f'[{self.module_name}]', f'input to {self.module_name} | x.shape  =', x.shape, self.training)\n",
        "        x1 = self.backbone1(x)\n",
        "        x2 = self.backbone2(x)\n",
        "        # x3 = self.backbone3(x)\n",
        "\n",
        "        if self.debug:\n",
        "            print(f'[{self.module_name}]', 'output of backbone1 | ', end='')\n",
        "            for level_out in x1:\n",
        "                print(tuple(level_out.shape), end=' | ')\n",
        "            print(f'\\n[{self.module_name}]', 'output of backbone2 | ', end='')\n",
        "            for level_out in x2:\n",
        "                print(tuple(level_out.shape), end=' | ')\n",
        "            # print(f'\\n[{self.module_name}]', 'output of backbone3 | ', end='')\n",
        "            # for level_out in x3:\n",
        "            #     print(tuple(level_out.shape), end=' | ')\n",
        "            print()\n",
        "\n",
        "        features_merged = []\n",
        "        # feature concatenation\n",
        "        for i in range(4):\n",
        "            if self.debug: print(f'[{self.module_name}]', i)\n",
        "            features_add = x1[i] + x2[i]\n",
        "            if self.debug: print(f'[{self.module_name}]', 'features_add.shape =', features_add.shape)\n",
        "            features_merged.append(features_add)\n",
        "\n",
        "        outs = []\n",
        "        # feature reduction\n",
        "        for i in range(4):\n",
        "            ith_features = features_merged[i]\n",
        "            if self.debug: print(f'[{self.module_name}]', i, ith_features.shape)\n",
        "            ith_block = self.blocks[i]\n",
        "            features_reduced = ith_block(ith_features)\n",
        "            if self.debug: print(f'[{self.module_name}]', 'features_reduced.shape =', features_reduced.shape)\n",
        "            outs.append(features_reduced)\n",
        "\n",
        "        return outs\n",
        "\n",
        "    def init_weights(self, pretrained=None):\n",
        "        print(f'[{self.module_name}]', 'pretrained -> ', pretrained)\n",
        "        if pretrained == None: return\n",
        "        pretrained = pretrained.split(';')\n",
        "        print(f'[{self.module_name}]', 'pretrained -> ', pretrained, pretrained[0])\n",
        "        self.backbone1.init_weights(pretrained[0])\n",
        "        self.backbone2.init_weights(pretrained[0])\n",
        "        # self.backbone3.init_weights(pretrained[1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_L69r5C5aYT"
      },
      "source": [
        "inputs = torch.rand(2, 3, 224, 224).to(device)\n",
        "pretrained = 'torchvision://resnet50;open-mmlab://resnext50_32x4d'\n",
        "lymphocyte_net = LymphocyteNet3_CM1(debug=True).to(device)\n",
        "print(lymphocyte_net)\n",
        "lymphocyte_net.init_weights(pretrained=pretrained)\n",
        "lymphocyte_net.eval()\n",
        "level_outputs = lymphocyte_net(inputs)\n",
        "for i, level in enumerate(level_outputs):\n",
        "    print(f'level{i} -> {level_outputs[i].shape}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu7bjIsM5aYz"
      },
      "source": [
        "### For File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKx3KQqV5aY1"
      },
      "source": [
        "backbone_file_data = r\"\"\"import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Module, Conv2d, BatchNorm2d, MaxPool2d, AvgPool2d, AdaptiveAvgPool2d, ReLU, Sequential, Linear, Dropout, Softmax\n",
        "from mmdet.models import BACKBONES, ResNet\n",
        "from mmdet.models.backbones.resnet_cbam import ResNetCBAM\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "class ChannelAttention2(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention2, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        self.fc1   = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2   = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
        "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
        "        out = avg_out + max_out\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class SpatialAttention2(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention2, self).__init__()\n",
        "\n",
        "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
        "        padding = 3 if kernel_size == 7 else 1\n",
        "\n",
        "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        x = torch.cat([avg_out, max_out], dim=1)\n",
        "        x = self.conv1(x)\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "class BasicBlock2(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, debug=False):\n",
        "        super(BasicBlock2, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.ca = ChannelAttention2(planes)\n",
        "        self.sa = SpatialAttention2()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out = self.ca(out) * out\n",
        "        out = self.sa(out) * out\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Bottleneck2(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, debug=False):\n",
        "        super(Bottleneck2, self).__init__()\n",
        "\n",
        "        self.module_name = 'Bottleneck2'\n",
        "        self.debug = debug\n",
        "\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes // 2, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes // 2)\n",
        "        self.conv2 = nn.Conv2d(planes // 2, planes // 2, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes // 2)\n",
        "        self.conv3 = nn.Conv2d(planes // 2, planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.ca = ChannelAttention2(planes)\n",
        "        self.sa = SpatialAttention2()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        if self.debug: print(f'[{self.module_name}][1] x.shape -> {x.shape}')\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        if self.debug: print(f'[{self.module_name}][2] out.shape -> {out.shape}')\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        if self.debug: print(f'[{self.module_name}][3] out.shape -> {out.shape}')\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        if self.debug: print(f'[{self.module_name}][4] out.shape -> {out.shape}')\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        out = self.ca(out) * out\n",
        "        if self.debug: print(f'[{self.module_name}][5] out.shape -> {out.shape}')\n",
        "        out = self.sa(out) * out\n",
        "        if self.debug: print(f'[{self.module_name}][6] out.shape -> {out.shape}')\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "            if self.debug: print(f'[{self.module_name}][7] residual.shape -> {residual.shape}')\n",
        "\n",
        "        out += residual\n",
        "        if self.debug: print(f'[{self.module_name}][8] out.shape -> {out.shape}')\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "@BACKBONES.register_module(force=True, name='LymphocyteNet3_CM1')\n",
        "class LymphocyteNet3_CM1(Module):\n",
        "    def __init__(self, debug, **kwargs):\n",
        "        super(LymphocyteNet3_CM1, self).__init__()\n",
        "        \n",
        "        self.debug = debug\n",
        "        self.module_name = 'LymphocyteNet3_CM1'\n",
        "        \n",
        "        self.backbone1 = ResNet(depth=50, num_stages=4, out_indices=(0, 1, 2, 3), frozen_stages=-1, norm_cfg=dict(type='BN', requires_grad=True), norm_eval=True, style='pytorch')\n",
        "        self.backbone2 = ResNetCBAM(depth=50, use_CBS=False, debug=False)\n",
        "        # self.backbone3 = ResNeXt(depth=50, num_stages=4, out_indices=(0, 1, 2, 3), frozen_stages=1, norm_cfg=dict(type='BN', requires_grad=True), norm_eval=True, style='pytorch', groups=32, base_width=4)\n",
        "\n",
        "        self.block1 = self._make_layer(Bottleneck2, 256, 256, 2, stride=1) #1 block inppace of 2\n",
        "        self.block2 = self._make_layer(Bottleneck2, 512, 512, 2, stride=1)\n",
        "        self.block3 = self._make_layer(Bottleneck2, 1024, 1024, 2, stride=1)\n",
        "        self.block4 = self._make_layer(Bottleneck2, 2048, 2048, 2, stride=1)\n",
        "\n",
        "        self.blocks = [self.block1, self.block2, self.block3, self.block4]\n",
        "\n",
        "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "\n",
        "        layers = [block(inplanes, planes, stride, downsample, debug=False)]\n",
        "        # inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(planes, planes, debug=False))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.debug: print(f'[{self.module_name}]', f'input to {self.module_name} | x.shape  =', x.shape, self.training)\n",
        "        x1 = self.backbone1(x)\n",
        "        x2 = self.backbone2(x)\n",
        "        # x3 = self.backbone3(x)\n",
        "\n",
        "        if self.debug:\n",
        "            print(f'[{self.module_name}]', 'output of backbone1 | ', end='')\n",
        "            for level_out in x1:\n",
        "                print(tuple(level_out.shape), end=' | ')\n",
        "            print(f'\\n[{self.module_name}]', 'output of backbone2 | ', end='')\n",
        "            for level_out in x2:\n",
        "                print(tuple(level_out.shape), end=' | ')\n",
        "            # print(f'\\n[{self.module_name}]', 'output of backbone3 | ', end='')\n",
        "            # for level_out in x3:\n",
        "            #     print(tuple(level_out.shape), end=' | ')\n",
        "            print()\n",
        "\n",
        "        features_merged = []\n",
        "        # feature concatenation\n",
        "        for i in range(4):\n",
        "            if self.debug: print(f'[{self.module_name}]', i)\n",
        "            features_add = x1[i] + x2[i]\n",
        "            if self.debug: print(f'[{self.module_name}]', 'features_add.shape =', features_add.shape)\n",
        "            features_merged.append(features_add)\n",
        "\n",
        "        outs = []\n",
        "        # feature reduction\n",
        "        for i in range(4):\n",
        "            ith_features = features_merged[i]\n",
        "            if self.debug: print(f'[{self.module_name}]', i, ith_features.shape)\n",
        "            ith_block = self.blocks[i]\n",
        "            features_reduced = ith_block(ith_features)\n",
        "            if self.debug: print(f'[{self.module_name}]', 'features_reduced.shape =', features_reduced.shape)\n",
        "            outs.append(features_reduced)\n",
        "\n",
        "        return outs\n",
        "\n",
        "    def init_weights(self, pretrained=None):\n",
        "        print(f'[{self.module_name}]', 'pretrained -> ', pretrained)\n",
        "        if pretrained == None: return\n",
        "        pretrained = pretrained.split(';')\n",
        "        print(f'[{self.module_name}]', 'pretrained -> ', pretrained)\n",
        "        self.backbone1.init_weights(pretrained[0])\n",
        "        self.backbone2.init_weights(pretrained[0])\n",
        "        # self.backbone3.init_weights(pretrained[1])\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "backbone_base_path = 'mmdet/models/backbones/'\n",
        "backbone_file_name = 'lymphocytenet3_CM1.py'\n",
        "backbone_file_path = os.path.join(backbone_base_path, backbone_file_name)\n",
        "with open(backbone_file_path, 'w') as backbone_file:\n",
        "    backbone_file.write(backbone_file_data)\n",
        "    print(f'<backbone_file_data> saved to \"{backbone_file_path}\"')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qp6RmXT5DZu"
      },
      "source": [
        "# Define Custom Hook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytSURp9Qwky_"
      },
      "source": [
        "## LymphCountEvalHook1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjkwMgC3EsFR"
      },
      "source": [
        "### For Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5k8VRqRNagX"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import ml_metrics as metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import mmcv\n",
        "from mmcv import Config\n",
        "from mmcv.runner import HOOKS, Hook\n",
        "from mmdet.apis import single_gpu_test\n",
        "\n",
        "from mmdet.datasets import build_dataloader, build_dataset, replace_ImageToTensor\n",
        "\n",
        "@HOOKS.register_module(force=True)\n",
        "class LymphCountEvalHook(Hook):\n",
        "    def __init__(self, path_config, base_dir):\n",
        "        self.hook_name = 'LymphCountEvalHook'\n",
        "        self.cfg = Config.fromfile(path_config)\n",
        "        self.base_dir = os.path.join(self.cfg.work_dir, base_dir)\n",
        "        self.metric_dir = os.path.join(self.base_dir, 'metrics')\n",
        "        self.plot_dir = os.path.join(self.base_dir, 'plots')\n",
        "        mmcv.mkdir_or_exist(self.metric_dir)\n",
        "        mmcv.mkdir_or_exist(self.plot_dir)\n",
        "        self.dataloader_val = self._build_dataloader(self.cfg.data, self.cfg.data.val)\n",
        "        self.dataloader_test = self._build_dataloader(self.cfg.data, self.cfg.data.test)\n",
        "\n",
        "    def _build_dataloader(self, cfg_data, data_type):\n",
        "        if cfg_data.samples_per_gpu > 1:\n",
        "            data_type.pipeline = replace_ImageToTensor(data_type.pipeline)\n",
        "        dataset = build_dataset(data_type)\n",
        "        data_loader = build_dataloader(\n",
        "            dataset,\n",
        "            samples_per_gpu=cfg_data.samples_per_gpu,\n",
        "            workers_per_gpu=cfg_data.workers_per_gpu,\n",
        "            dist=False,\n",
        "            shuffle=False)\n",
        "        return data_loader\n",
        "\n",
        "    def eval_sepcific_epoch(self, model, epoch=0):\n",
        "        self.epoch = epoch\n",
        "        print(f'[{self.hook_name}] epoch={self.epoch}')\n",
        "        self._perform_evaluation(model)\n",
        "\n",
        "    def before_epoch(self, runner):\n",
        "        self.epoch = runner.epoch + 1\n",
        "        print(f'[{self.hook_name}] epoch={self.epoch}')\n",
        "        # if self.epoch == 1:\n",
        "        #     self._perform_evaluation(runner.model)\n",
        "\n",
        "    def after_epoch(self, runner):\n",
        "        self.epoch = runner.epoch + 1\n",
        "        print(f'[{self.hook_name}] epoch={self.epoch}')\n",
        "        if self.epoch % self.eval_interval == 0 or self.epoch == self.cfg.total_epochs:\n",
        "            self._perform_evaluation(runner.model)\n",
        "\n",
        "    def _perform_evaluation(self, model):\n",
        "        outputs_test = single_gpu_test(model, self.dataloader_test, False, False, 0.3)\n",
        "        print('[_perform_evaluation]')\n",
        "        # for d in [0, 12]:\n",
        "        #     eval_metrics = self._calculate('test', self.dataloader_test.dataset, outputs_test, distance=d)\n",
        "        #     thresholds_test, recalls_test, precisions_test, fscores_test, kappas_test, accuracies_test = eval_metrics\n",
        "        #     self._save('test', thresholds_test, recalls_test, precisions_test, fscores_test, kappas_test, accuracies_test, distance=d)\n",
        "        #     self._plot('test', thresholds_test, recalls_test, precisions_test, fscores_test, kappas_test, accuracies_test, distance=d)\n",
        "        thresholds_val, recalls_val, precisions_val, accuracies_val, f_scores_val = self._calculate(None, 'val', self.dataloader_val.dataset, outputs_val)\n",
        "        self._save(None, 'val', thresholds_val, recalls_val, precisions_val, accuracies_val, f_scores_val, self.dataloader_val.dataset, outputs_val)\n",
        "        self._plot(None, 'val', thresholds_val, recalls_val, precisions_val, accuracies_val, f_scores_val)\n",
        "\n",
        "        thresholds_test, recalls_test, precisions_test, accuracies_test, f_scores_test = self._calculate(None, 'test', self.dataloader_test.dataset, outputs_test)\n",
        "        self._save(None, 'test', thresholds_test, recalls_test, precisions_test, accuracies_test, f_scores_test, self.dataloader_test.dataset, outputs_test)\n",
        "        self._plot(None, 'test', thresholds_test, recalls_test, precisions_test, accuracies_test, f_scores_test)\n",
        "\n",
        "    # def after_epoch(self, runner):\n",
        "    #     self.epoch = runner.epoch + 1\n",
        "    #     print(f'[{self.hook_name}] epoch={self.epoch}')\n",
        "\n",
        "    #     if self.epoch % 4 == 0:\n",
        "    #         # results_val = single_gpu_test(runner.model, self.dataloader_val, show=False)\n",
        "    #         # thresholds_val, recalls_val, precisions_val, accuracies_val, f_scores_val = self._calculate(runner, 'val', self.dataloader_val.dataset, results_val)\n",
        "    #         # self._save(runner, 'val', thresholds_val, recalls_val, precisions_val, accuracies_val, f_scores_val, self.dataloader_val.dataset, results_val)\n",
        "    #         # self._plot(runner, 'val', thresholds_val, recalls_val, precisions_val, accuracies_val, f_scores_val)\n",
        "\n",
        "    #         results_test = single_gpu_test(runner.model, self.dataloader_test, show=False)\n",
        "    #         thresholds_test, recalls_test, precisions_test, accuracies_test, f_scores_test = self._calculate(runner, 'test', self.dataloader_test.dataset, results_test)\n",
        "    #         self._save(runner, 'test', thresholds_test, recalls_test, precisions_test, accuracies_val, f_scores_test, self.dataloader_test.dataset, results_test)\n",
        "    #         self._plot(runner, 'test', thresholds_test, recalls_test, precisions_test, accuracies_val, f_scores_test)\n",
        "\n",
        "    def _calculate(self, runner, datatype, dataset, results):\n",
        "        step_size = 0.01\n",
        "        thresholds = np.arange(0.0, 1 + step_size, step_size)\n",
        "        recalls = []\n",
        "        precisions = []\n",
        "        accuracies = []\n",
        "        f_scores = []\n",
        "\n",
        "        for threshold in mmcv.track_iter_progress(thresholds):\n",
        "            confusion_matrix = np.array([[0, 0], [0, 0]])\n",
        "\n",
        "            for i, image_id in enumerate(dataset.img_ids):\n",
        "                gt_count = len(dataset.get_ann_info(image_id)['bboxes'])\n",
        "                dt_count = np.sum(results[image_id][0][0][:, 4] > threshold)\n",
        "                if gt_count == dt_count:\n",
        "                    confusion_matrix[0][0] += gt_count\n",
        "                elif gt_count > dt_count:\n",
        "                    confusion_matrix[0][0] += dt_count\n",
        "                    confusion_matrix[1][0] += np.abs(gt_count - dt_count)\n",
        "                elif gt_count < dt_count:\n",
        "                    confusion_matrix[0][0] += gt_count\n",
        "                    confusion_matrix[0][1] += np.abs(gt_count - dt_count)\n",
        "\n",
        "            TP = confusion_matrix[0][0]\n",
        "            FP = confusion_matrix[0][1]\n",
        "            FN = confusion_matrix[1][0]\n",
        "\n",
        "            recall = TP / (TP + FN)\n",
        "            precision = TP / (TP + FP)\n",
        "            precision = precision if not np.isnan(precision) else 1\n",
        "            accuracy = TP / (TP + FP + FN)\n",
        "            f_score = 2 * precision * recall / (precision + recall)\n",
        "            \n",
        "            recalls.append(recall)\n",
        "            precisions.append(precision)\n",
        "            accuracies.append(accuracy)\n",
        "            f_scores.append(f_score)\n",
        "\n",
        "        return thresholds, np.array(recalls), np.array(precisions), np.array(accuracies), np.array(f_scores)\n",
        "\n",
        "    def _save(self, runner, datatype, thresholds, recalls, precisions, accuracies, f_scores, dataset, results):\n",
        "        index_max_f_score = np.argmax(f_scores)\n",
        "        save_string  = f'{datatype}-set\\n'\n",
        "        save_string += f'threshold=0.5:0.95 | recall={np.average(recalls[50:96]):1.8f} | precision={np.average(precisions[50:96]):1.8f} | accuracy={np.average(accuracies[50:96]):1.8f} | f-score={np.average(f_scores[50:96]):1.8f}\\n'\n",
        "        save_string += f'threshold=0.25     | recall={recalls[25]:1.8f} | precision={precisions[25]:1.8f} | accuracy={accuracies[25]:1.8f} | f-score={f_scores[25]:1.8f}\\n'\n",
        "        save_string += f'threshold=0.50     | recall={recalls[50]:1.8f} | precision={precisions[50]:1.8f} | accuracy={accuracies[50]:1.8f} | f-score={f_scores[50]:1.8f}\\n'\n",
        "        save_string += f'threshold=0.75     | recall={recalls[75]:1.8f} | precision={precisions[75]:1.8f} | accuracy={accuracies[75]:1.8f} | f-score={f_scores[75]:1.8f}\\n'\n",
        "        save_string += f'threshold=0.95     | recall={recalls[95]:1.8f} | precision={precisions[95]:1.8f} | accuracy={accuracies[95]:1.8f} | f-score={f_scores[95]:1.8f}\\n'\n",
        "        save_string += f'threshold={thresholds[index_max_f_score]:1.2f}     | recall={recalls[index_max_f_score]:1.8f} | precision={precisions[index_max_f_score]:1.8f} | accuracy={accuracies[index_max_f_score]:1.8f} | f-score={np.max(f_scores):1.8f}\\n'\n",
        "        # quadratic_weighted_kappa = self._calculate_quadratic_weighted_kappa(runner, datatype, thresholds, dataset, results, f_scores)\n",
        "        # save_string += f'quadratic_weighted_kappa={quadratic_weighted_kappa}\\n\\n'\n",
        "        print(save_string)\n",
        "        with open(os.path.join(self.metric_dir, f'maskrcnn-lymphocytenet3-cm1-e{self.epoch:03}.txt'), 'a') as save_file:\n",
        "            save_file.write(save_string)\n",
        "\n",
        "    def _calculate_quadratic_weighted_kappa(self, runner, datatype, thresholds, dataset, results, f_scores):\n",
        "        gt_counts = []\n",
        "        dt_counts = []\n",
        "        threshold = thresholds[np.argmax(f_scores)]\n",
        "        confusion_matrix = np.array([[0, 0], [0, 0]])\n",
        "\n",
        "        for i, image_id in enumerate(dataset.img_ids):\n",
        "            gt_count = len(dataset.get_ann_info(image_id)['bboxes'])\n",
        "            dt_count = np.sum(results[image_id][0][0][:, 4] > threshold)\n",
        "            gt_counts.append(gt_count)\n",
        "            dt_counts.append(dt_count)\n",
        "        return metrics.quadratic_weighted_kappa(gt_counts, dt_counts)\n",
        "\n",
        "    def _plot(self, runner, datatype, thresholds, recalls, precisions, accuracies, f_scores):\n",
        "        plt.figure(figsize=(15, 15))\n",
        "\n",
        "        ax = plt.subplot(2, 2, 1)\n",
        "        ax.title.set_text('thresholds vs recalls')\n",
        "        ax.set_xlabel('threshold')\n",
        "        ax.set_ylabel('recall')\n",
        "        plt.plot(thresholds, recalls)\n",
        "        # plt.scatter(thresholds, recalls)\n",
        "\n",
        "        ax = plt.subplot(2, 2, 2)\n",
        "        ax.title.set_text('thresholds vs precisions')\n",
        "        ax.set_xlabel('threshold')\n",
        "        ax.set_ylabel('precision')\n",
        "        plt.plot(thresholds, precisions)\n",
        "        # plt.scatter(thresholds, precisions)\n",
        "\n",
        "        ax = plt.subplot(2, 2, 3)\n",
        "        ax.title.set_text('thresholds vs f_scores')\n",
        "        ax.set_xlabel('threshold')\n",
        "        ax.set_ylabel('f_scores')\n",
        "        plt.plot(thresholds, f_scores)\n",
        "        # plt.scatter(thresholds, f_scores)\n",
        "\n",
        "        ax = plt.subplot(2, 2, 4)\n",
        "        ax.title.set_text('recalls vs precisions')\n",
        "        ax.set_xlabel('recall')\n",
        "        ax.set_ylabel('precision')\n",
        "        plt.plot(recalls, precisions)\n",
        "        # plt.scatter(recalls, precisions)\n",
        "\n",
        "        index_max_f_score = np.argmax(f_scores)\n",
        "        plt.plot([recalls[index_max_f_score], recalls[index_max_f_score]], [0, 1])\n",
        "        plt.plot([0, 1], [precisions[index_max_f_score], precisions[index_max_f_score]])\n",
        "        plt.savefig(os.path.join(self.plot_dir, f'maskrcnn-resnet50-multidilation-{datatype}-e{self.epoch}.png'), dpi=300)\n",
        "        \n",
        "        plt.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-CVnSnPE22V"
      },
      "source": [
        "### For File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqvLXviUaYdE"
      },
      "source": [
        "custom_eval_hook_file_data = r\"\"\"import os\n",
        "import numpy as np\n",
        "import ml_metrics as metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import mmcv\n",
        "from mmcv import Config\n",
        "from mmcv.runner import HOOKS, Hook\n",
        "from mmdet.apis import single_gpu_test\n",
        "\n",
        "from mmdet.datasets import build_dataloader, build_dataset, replace_ImageToTensor\n",
        "\n",
        "@HOOKS.register_module(force=True)\n",
        "class LymphCountEvalHook(Hook):\n",
        "    def __init__(self, path_config, base_dir):\n",
        "        self.hook_name = 'LymphCountEvalHook'\n",
        "        self.cfg = Config.fromfile(path_config)\n",
        "        self.base_dir = os.path.join(self.cfg.work_dir, base_dir)\n",
        "        self.metric_dir = os.path.join(self.base_dir, 'metrics')\n",
        "        self.plot_dir = os.path.join(self.base_dir, 'plots')\n",
        "        mmcv.mkdir_or_exist(self.metric_dir)\n",
        "        mmcv.mkdir_or_exist(self.plot_dir)\n",
        "        self.dataloader_val = self._build_dataloader(self.cfg.data, self.cfg.data.val)\n",
        "        self.dataloader_test = self._build_dataloader(self.cfg.data, self.cfg.data.test)\n",
        "\n",
        "    def _build_dataloader(self, cfg_data, data_type):\n",
        "        if cfg_data.samples_per_gpu > 1:\n",
        "            data_type.pipeline = replace_ImageToTensor(data_type.pipeline)\n",
        "        dataset = build_dataset(data_type)\n",
        "        data_loader = build_dataloader(\n",
        "            dataset,\n",
        "            samples_per_gpu=cfg_data.samples_per_gpu,\n",
        "            workers_per_gpu=cfg_data.workers_per_gpu,\n",
        "            dist=False,\n",
        "            shuffle=False)\n",
        "        return data_loader\n",
        "\n",
        "    def eval_sepcific_epoch(self, model, epoch=0):\n",
        "        self.epoch = epoch\n",
        "        print(f'[{self.hook_name}] epoch={self.epoch}')\n",
        "        self._perform_evaluation(model)\n",
        "\n",
        "    def before_epoch(self, runner):\n",
        "        self.epoch = runner.epoch + 1\n",
        "        print(f'[{self.hook_name}] epoch={self.epoch}')\n",
        "        # if self.epoch == 1:\n",
        "        #     self._perform_evaluation(runner.model)\n",
        "\n",
        "    def after_epoch(self, runner):\n",
        "        self.epoch = runner.epoch + 1\n",
        "        print(f'[{self.hook_name}] epoch={self.epoch}')\n",
        "        if self.epoch % self.eval_interval == 0 or self.epoch == self.cfg.total_epochs:\n",
        "            self._perform_evaluation(runner.model)\n",
        "\n",
        "    def _perform_evaluation(self, model):\n",
        "        outputs_test = single_gpu_test(model, self.dataloader_test, False, False, 0.3)\n",
        "        print('[_perform_evaluation]')\n",
        "        # for d in [0, 12]:\n",
        "        #     eval_metrics = self._calculate('test', self.dataloader_test.dataset, outputs_test, distance=d)\n",
        "        #     thresholds_test, recalls_test, precisions_test, fscores_test, kappas_test, accuracies_test = eval_metrics\n",
        "        #     self._save('test', thresholds_test, recalls_test, precisions_test, fscores_test, kappas_test, accuracies_test, distance=d)\n",
        "        #     self._plot('test', thresholds_test, recalls_test, precisions_test, fscores_test, kappas_test, accuracies_test, distance=d)\n",
        "        thresholds_val, recalls_val, precisions_val, accuracies_val, f_scores_val = self._calculate(None, 'val', self.dataloader_val.dataset, outputs_val)\n",
        "        self._save(None, 'val', thresholds_val, recalls_val, precisions_val, accuracies_val, f_scores_val, self.dataloader_val.dataset, outputs_val)\n",
        "        self._plot(None, 'val', thresholds_val, recalls_val, precisions_val, accuracies_val, f_scores_val)\n",
        "\n",
        "        thresholds_test, recalls_test, precisions_test, accuracies_test, f_scores_test = self._calculate(None, 'test', self.dataloader_test.dataset, outputs_test)\n",
        "        self._save(None, 'test', thresholds_test, recalls_test, precisions_test, accuracies_test, f_scores_test, self.dataloader_test.dataset, outputs_test)\n",
        "        self._plot(None, 'test', thresholds_test, recalls_test, precisions_test, accuracies_test, f_scores_test)\n",
        "\n",
        "    # def after_epoch(self, runner):\n",
        "    #     self.epoch = runner.epoch + 1\n",
        "    #     print(f'[{self.hook_name}] epoch={self.epoch}')\n",
        "\n",
        "    #     if self.epoch % 4 == 0:\n",
        "    #         # results_val = single_gpu_test(runner.model, self.dataloader_val, show=False)\n",
        "    #         # thresholds_val, recalls_val, precisions_val, accuracies_val, f_scores_val = self._calculate(runner, 'val', self.dataloader_val.dataset, results_val)\n",
        "    #         # self._save(runner, 'val', thresholds_val, recalls_val, precisions_val, accuracies_val, f_scores_val, self.dataloader_val.dataset, results_val)\n",
        "    #         # self._plot(runner, 'val', thresholds_val, recalls_val, precisions_val, accuracies_val, f_scores_val)\n",
        "\n",
        "    #         results_test = single_gpu_test(runner.model, self.dataloader_test, show=False)\n",
        "    #         thresholds_test, recalls_test, precisions_test, accuracies_test, f_scores_test = self._calculate(runner, 'test', self.dataloader_test.dataset, results_test)\n",
        "    #         self._save(runner, 'test', thresholds_test, recalls_test, precisions_test, accuracies_val, f_scores_test, self.dataloader_test.dataset, results_test)\n",
        "    #         self._plot(runner, 'test', thresholds_test, recalls_test, precisions_test, accuracies_val, f_scores_test)\n",
        "\n",
        "    def _calculate(self, runner, datatype, dataset, results):\n",
        "        step_size = 0.01\n",
        "        thresholds = np.arange(0.0, 1 + step_size, step_size)\n",
        "        recalls = []\n",
        "        precisions = []\n",
        "        accuracies = []\n",
        "        f_scores = []\n",
        "\n",
        "        for threshold in mmcv.track_iter_progress(thresholds):\n",
        "            confusion_matrix = np.array([[0, 0], [0, 0]])\n",
        "\n",
        "            for i, image_id in enumerate(dataset.img_ids):\n",
        "                gt_count = len(dataset.get_ann_info(image_id)['bboxes'])\n",
        "                dt_count = np.sum(results[image_id][0][0][:, 4] > threshold)\n",
        "                if gt_count == dt_count:\n",
        "                    confusion_matrix[0][0] += gt_count\n",
        "                elif gt_count > dt_count:\n",
        "                    confusion_matrix[0][0] += dt_count\n",
        "                    confusion_matrix[1][0] += np.abs(gt_count - dt_count)\n",
        "                elif gt_count < dt_count:\n",
        "                    confusion_matrix[0][0] += gt_count\n",
        "                    confusion_matrix[0][1] += np.abs(gt_count - dt_count)\n",
        "\n",
        "            TP = confusion_matrix[0][0]\n",
        "            FP = confusion_matrix[0][1]\n",
        "            FN = confusion_matrix[1][0]\n",
        "\n",
        "            recall = TP / (TP + FN)\n",
        "            precision = TP / (TP + FP)\n",
        "            precision = precision if not np.isnan(precision) else 1\n",
        "            accuracy = TP / (TP + FP + FN)\n",
        "            f_score = 2 * precision * recall / (precision + recall)\n",
        "            \n",
        "            recalls.append(recall)\n",
        "            precisions.append(precision)\n",
        "            accuracies.append(accuracy)\n",
        "            f_scores.append(f_score)\n",
        "\n",
        "        return thresholds, np.array(recalls), np.array(precisions), np.array(accuracies), np.array(f_scores)\n",
        "\n",
        "    def _save(self, runner, datatype, thresholds, recalls, precisions, accuracies, f_scores, dataset, results):\n",
        "        index_max_f_score = np.argmax(f_scores)\n",
        "        save_string  = f'{datatype}-set\\n'\n",
        "        save_string += f'threshold=0.5:0.95 | recall={np.average(recalls[50:96]):1.8f} | precision={np.average(precisions[50:96]):1.8f} | accuracy={np.average(accuracies[50:96]):1.8f} | f-score={np.average(f_scores[50:96]):1.8f}\\n'\n",
        "        save_string += f'threshold=0.25     | recall={recalls[25]:1.8f} | precision={precisions[25]:1.8f} | accuracy={accuracies[25]:1.8f} | f-score={f_scores[25]:1.8f}\\n'\n",
        "        save_string += f'threshold=0.50     | recall={recalls[50]:1.8f} | precision={precisions[50]:1.8f} | accuracy={accuracies[50]:1.8f} | f-score={f_scores[50]:1.8f}\\n'\n",
        "        save_string += f'threshold=0.75     | recall={recalls[75]:1.8f} | precision={precisions[75]:1.8f} | accuracy={accuracies[75]:1.8f} | f-score={f_scores[75]:1.8f}\\n'\n",
        "        save_string += f'threshold=0.95     | recall={recalls[95]:1.8f} | precision={precisions[95]:1.8f} | accuracy={accuracies[95]:1.8f} | f-score={f_scores[95]:1.8f}\\n'\n",
        "        save_string += f'threshold={thresholds[index_max_f_score]:1.2f}     | recall={recalls[index_max_f_score]:1.8f} | precision={precisions[index_max_f_score]:1.8f} | accuracy={accuracies[index_max_f_score]:1.8f} | f-score={np.max(f_scores):1.8f}\\n'\n",
        "        # quadratic_weighted_kappa = self._calculate_quadratic_weighted_kappa(runner, datatype, thresholds, dataset, results, f_scores)\n",
        "        # save_string += f'quadratic_weighted_kappa={quadratic_weighted_kappa}\\n\\n'\n",
        "        print(save_string)\n",
        "        with open(os.path.join(self.metric_dir, f'maskrcnn-lymphocytenet3-cm1-e{self.epoch:03}.txt'), 'a') as save_file:\n",
        "            save_file.write(save_string)\n",
        "\n",
        "    def _calculate_quadratic_weighted_kappa(self, runner, datatype, thresholds, dataset, results, f_scores):\n",
        "        gt_counts = []\n",
        "        dt_counts = []\n",
        "        threshold = thresholds[np.argmax(f_scores)]\n",
        "        confusion_matrix = np.array([[0, 0], [0, 0]])\n",
        "\n",
        "        for i, image_id in enumerate(dataset.img_ids):\n",
        "            gt_count = len(dataset.get_ann_info(image_id)['bboxes'])\n",
        "            dt_count = np.sum(results[image_id][0][0][:, 4] > threshold)\n",
        "            gt_counts.append(gt_count)\n",
        "            dt_counts.append(dt_count)\n",
        "        return metrics.quadratic_weighted_kappa(gt_counts, dt_counts)\n",
        "\n",
        "    def _plot(self, runner, datatype, thresholds, recalls, precisions, accuracies, f_scores):\n",
        "        plt.figure(figsize=(15, 15))\n",
        "\n",
        "        ax = plt.subplot(2, 2, 1)\n",
        "        ax.title.set_text('thresholds vs recalls')\n",
        "        ax.set_xlabel('threshold')\n",
        "        ax.set_ylabel('recall')\n",
        "        plt.plot(thresholds, recalls)\n",
        "        # plt.scatter(thresholds, recalls)\n",
        "\n",
        "        ax = plt.subplot(2, 2, 2)\n",
        "        ax.title.set_text('thresholds vs precisions')\n",
        "        ax.set_xlabel('threshold')\n",
        "        ax.set_ylabel('precision')\n",
        "        plt.plot(thresholds, precisions)\n",
        "        # plt.scatter(thresholds, precisions)\n",
        "\n",
        "        ax = plt.subplot(2, 2, 3)\n",
        "        ax.title.set_text('thresholds vs f_scores')\n",
        "        ax.set_xlabel('threshold')\n",
        "        ax.set_ylabel('f_scores')\n",
        "        plt.plot(thresholds, f_scores)\n",
        "        # plt.scatter(thresholds, f_scores)\n",
        "\n",
        "        ax = plt.subplot(2, 2, 4)\n",
        "        ax.title.set_text('recalls vs precisions')\n",
        "        ax.set_xlabel('recall')\n",
        "        ax.set_ylabel('precision')\n",
        "        plt.plot(recalls, precisions)\n",
        "        # plt.scatter(recalls, precisions)\n",
        "\n",
        "        index_max_f_score = np.argmax(f_scores)\n",
        "        plt.plot([recalls[index_max_f_score], recalls[index_max_f_score]], [0, 1])\n",
        "        plt.plot([0, 1], [precisions[index_max_f_score], precisions[index_max_f_score]])\n",
        "        plt.savefig(os.path.join(self.plot_dir, f'maskrcnn-resnet50-multidilation-{datatype}-e{self.epoch}.png'), dpi=300)\n",
        "        \n",
        "        plt.close()\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "custom_eval_hook_base_path = 'mmdet/core/utils/'\n",
        "custom_eval_hook_file_name = 'lymph_count_eval_hook.py'\n",
        "custom_eval_hook_file_path = os.path.join(custom_eval_hook_base_path, custom_eval_hook_file_name)\n",
        "with open(custom_eval_hook_file_path, 'w') as custom_eval_hook_file:\n",
        "    custom_eval_hook_file.write(custom_eval_hook_file_data)\n",
        "    print(f'<custom_eval_hook_file_data> saved to \"{custom_eval_hook_file_path}\"')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDpVow2DZhzn"
      },
      "source": [
        "## LymphCountEvalHook2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvr2LGm85DZ5"
      },
      "source": [
        "### Colab Version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihnQRTz-5DZ6"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ml_metrics as metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import mmcv\n",
        "from mmcv import Config\n",
        "from mmcv.runner import HOOKS, Hook\n",
        "from mmdet.apis import single_gpu_test\n",
        "\n",
        "from mmdet.datasets import build_dataloader, build_dataset, replace_ImageToTensor\n",
        "\n",
        "@HOOKS.register_module(name='LymphCountEvalHook', force=True)\n",
        "class LymphCountEvalHook(Hook):\n",
        "    def __init__(self, eval_interval, file_prefix, path_config, base_dir):\n",
        "        self.hook_name = 'LymphCountEvalHook'\n",
        "        self.eval_interval = eval_interval\n",
        "        self.file_prefix = file_prefix\n",
        "        self.cfg = Config.fromfile(path_config)\n",
        "        self.cfg.data.samples_per_gpu = 1\n",
        "        self.cfg.data.workers_per_gpu = 1\n",
        "        self.base_dir = os.path.join(self.cfg.work_dir, base_dir)\n",
        "        self.metric_dir = os.path.join(self.base_dir, 'metrics')\n",
        "        self.statistics = os.path.join(self.base_dir, 'statistics')\n",
        "        self.plot_dir = os.path.join(self.base_dir, 'plots')\n",
        "        mmcv.mkdir_or_exist(self.metric_dir)\n",
        "        mmcv.mkdir_or_exist(self.statistics)\n",
        "        mmcv.mkdir_or_exist(self.plot_dir)\n",
        "        self.dataloader_test = self._build_dataloader(self.cfg.data, self.cfg.data.test)\n",
        "\n",
        "    def _build_dataloader(self, cfg_data, data_type):\n",
        "        if isinstance(data_type, dict):\n",
        "            data_type.test_mode = True\n",
        "        elif isinstance(data_type, list):\n",
        "            for ds_cfg in data_type:\n",
        "                ds_cfg.test_mode = True\n",
        "        if cfg_data.samples_per_gpu > 1:\n",
        "            data_type.pipeline = replace_ImageToTensor(data_type.pipeline)\n",
        "        dataset = build_dataset(data_type)\n",
        "        data_loader = build_dataloader(\n",
        "            dataset,\n",
        "            samples_per_gpu=cfg_data.samples_per_gpu,\n",
        "            workers_per_gpu=cfg_data.workers_per_gpu,\n",
        "            dist=False,\n",
        "            shuffle=False)\n",
        "        return data_loader\n",
        "\n",
        "    def eval_sepcific_epoch(self, model, epoch=0):\n",
        "        self.epoch = epoch\n",
        "        print(f'[{self.hook_name}] epoch={self.epoch}')\n",
        "        self._perform_evaluation(model)\n",
        "\n",
        "    def before_epoch(self, runner):\n",
        "        self.epoch = runner.epoch + 1\n",
        "        print(f'[{self.hook_name}] epoch={self.epoch}')\n",
        "        # if self.epoch == 1:\n",
        "        #     self._perform_evaluation(runner.model)\n",
        "\n",
        "    def after_epoch(self, runner):\n",
        "        self.epoch = runner.epoch + 1\n",
        "        print(f'[{self.hook_name}] epoch={self.epoch}')\n",
        "        if self.epoch % self.eval_interval == 0 or self.epoch == self.cfg.total_epochs:\n",
        "            self._perform_evaluation(runner.model)\n",
        "\n",
        "    def _perform_evaluation(self, model):\n",
        "        outputs_test = single_gpu_test(model, self.dataloader_test, False, False, 0.3)\n",
        "        print()\n",
        "        for d in [0, 12]:\n",
        "            eval_metrics = self._calculate('test', self.dataloader_test.dataset, outputs_test, distance=d)\n",
        "            thresholds_test, recalls_test, precisions_test, fscores_test, kappas_test, accuracies_test = eval_metrics\n",
        "            self._save('test', thresholds_test, recalls_test, precisions_test, fscores_test, kappas_test, accuracies_test, distance=d)\n",
        "            self._plot('test', thresholds_test, recalls_test, precisions_test, fscores_test, kappas_test, accuracies_test, distance=d)\n",
        "\n",
        "    def _calculate(self, datatype, dataset, outputs, distance):\n",
        "        step_size = 0.01\n",
        "        thresholds = np.arange(0.0, 1 + step_size, step_size)\n",
        "        classes = self.cfg.classes\n",
        "        recalls = np.zeros((len(classes), len(thresholds)))\n",
        "        precisions = np.zeros((len(classes), len(thresholds)))\n",
        "        fscores = np.zeros((len(classes), len(thresholds)))\n",
        "        kappas = np.zeros((len(classes), len(thresholds)))\n",
        "        accuracies = np.zeros((len(classes), len(thresholds)))\n",
        "        statistics_thresholds = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "        \n",
        "        columns = ['class_id', 'class_label', 'threshold', 'image_id', 'image_name', 'gt_count', 'dt_count', 'TP', 'FP', 'FN', 'distance']\n",
        "        image_statistics = {key: [] for key in columns}\n",
        "        for class_id, class_label in enumerate(classes):\n",
        "            print(f'[{self.hook_name}] d={distance}, class_id={class_id}, class_label={class_label}')\n",
        "            for threshold_index, threshold in enumerate(mmcv.track_iter_progress(thresholds)):\n",
        "                confusion_matrix = np.array([[0, 0], [0, 0]])\n",
        "                kappa_gt_counts, kappa_dt_counts = [], []\n",
        "                for i, idx in enumerate(dataset.img_ids):\n",
        "                    image_id = dataset.img_ids[idx]\n",
        "                    image_name = dataset.data_infos[image_id]['filename']\n",
        "                    gt_count = len(dataset.get_ann_info(image_id)['bboxes'])\n",
        "                    kappa_gt_counts.append(gt_count)\n",
        "                    output = outputs[idx][0]\n",
        "                    scores = output[class_id][:, 4]\n",
        "                    bboxes = output[class_id][:, :4]\n",
        "                    bboxes = bboxes[np.where(scores > threshold)[0]]\n",
        "                    dt_count1 = int(len(bboxes))\n",
        "\n",
        "                    centroid_x = (bboxes[:, 0] + bboxes[:, 2]) / 2\n",
        "                    centroid_y = (bboxes[:, 1] + bboxes[:, 3]) / 2\n",
        "                    merged = []\n",
        "                    if distance > 0:\n",
        "                        for j in range(0, dt_count1 - 1):\n",
        "                            if j not in merged:\n",
        "                                for k in range(j + 1, dt_count1):\n",
        "                                    _distance = int(np.sqrt(np.square(centroid_x[j] - centroid_x[k]) + np.square(centroid_y[j] - centroid_y[k])))\n",
        "                                    if _distance <= distance:\n",
        "                                        merged.append(k)\n",
        "\n",
        "                    dt_count2 = dt_count1 - len(merged)\n",
        "                    kappa_dt_counts.append(dt_count2)\n",
        "                    image_TP, image_FP, image_FN = 0, 0, 0\n",
        "                    if gt_count == dt_count2:\n",
        "                        image_TP = gt_count\n",
        "                    elif gt_count > dt_count2:\n",
        "                        image_TP = dt_count2\n",
        "                        image_FN = np.abs(gt_count - dt_count2)\n",
        "                    elif gt_count < dt_count2:\n",
        "                        image_TP = gt_count\n",
        "                        image_FP = np.abs(gt_count - dt_count2)\n",
        "\n",
        "                    confusion_matrix[0][0] += image_TP\n",
        "                    confusion_matrix[0][1] += image_FP\n",
        "                    confusion_matrix[1][0] += image_FN\n",
        "                    \n",
        "                    if threshold in statistics_thresholds:\n",
        "                        image_statistics['class_id'].append(class_id)\n",
        "                        image_statistics['class_label'].append(class_label)\n",
        "                        image_statistics['threshold'].append(threshold)\n",
        "                        image_statistics['image_id'].append(image_id)\n",
        "                        image_statistics['image_name'].append(image_name)\n",
        "                        image_statistics['gt_count'].append(gt_count)\n",
        "                        image_statistics['dt_count'].append(dt_count2)\n",
        "                        image_statistics['TP'].append(image_TP)\n",
        "                        image_statistics['FP'].append(image_FP)\n",
        "                        image_statistics['FN'].append(image_FN)\n",
        "                        image_statistics['distance'].append(distance)\n",
        "\n",
        "                TP = confusion_matrix[0][0]\n",
        "                FP = confusion_matrix[0][1]\n",
        "                FN = confusion_matrix[1][0]\n",
        "\n",
        "                recall = TP / (TP + FN)\n",
        "                precision = TP / (TP + FP)\n",
        "                precision = precision if not np.isnan(precision) else 1\n",
        "                fscore = 2 * precision * recall / (precision + recall)\n",
        "                kappa = metrics.quadratic_weighted_kappa(kappa_gt_counts, kappa_dt_counts)\n",
        "                accuracy = TP / (TP + FP + FN)\n",
        "\n",
        "                recalls[class_id][threshold_index] = recall\n",
        "                precisions[class_id][threshold_index] = precision\n",
        "                fscores[class_id][threshold_index] = fscore\n",
        "                kappas[class_id][threshold_index] = kappa\n",
        "                accuracies[class_id][threshold_index] = accuracy\n",
        "            print()\n",
        "\n",
        "        df_statistics = pd.DataFrame(image_statistics, columns=columns)\n",
        "        df_statistics.to_csv(os.path.join(self.statistics, f'd{distance:02}-{self.file_prefix}-{datatype}-e{self.epoch:03}.csv'))\n",
        "        return thresholds, np.array(recalls), np.array(precisions), np.array(fscores), np.array(kappas), np.array(accuracies)\n",
        "\n",
        "    def _save(self, datatype, thresholds, recalls, precisions, fscores, kappas, accuracies, distance):\n",
        "        classes = self.cfg.classes\n",
        "        coco_thresholds = {'threshold=0.5:0.95': np.arange(50, 96), 'threshold=0.25': 25, 'threshold=0.50': 50, 'threshold=0.75': 75, 'threshold=0.95': 95, 'threshold-max_fscore': -1}\n",
        "        columns = ['class_label', 'threshold', 'recall', 'precision', 'fscore', 'kappa', 'accuracy']\n",
        "        df_metrics = pd.DataFrame(index=range(len(classes) * len(coco_thresholds.keys())), columns=columns, dtype=np.float32)\n",
        "        df_metrics = df_metrics.fillna(0)\n",
        "        for class_id, class_label in enumerate(classes):\n",
        "            for threshold_idx, threshold in enumerate(coco_thresholds):\n",
        "                idx = int(class_id * len(coco_thresholds.keys()) + threshold_idx)\n",
        "                threshold_range = coco_thresholds[threshold]\n",
        "                if threshold == 'threshold-max_fscore':\n",
        "                    threshold_range = np.argmax(fscores[class_id])\n",
        "                df_metrics.loc[idx, columns[0]] = class_label\n",
        "                df_metrics.loc[idx, columns[1]] = threshold\n",
        "                df_metrics.loc[idx, columns[2]] = np.average(recalls[class_id, threshold_range])\n",
        "                df_metrics.loc[idx, columns[3]] = np.average(precisions[class_id, threshold_range])\n",
        "                df_metrics.loc[idx, columns[4]] = np.average(fscores[class_id, threshold_range])\n",
        "                df_metrics.loc[idx, columns[5]] = np.average(kappas[class_id, threshold_range])\n",
        "                df_metrics.loc[idx, columns[6]] = np.average(accuracies[class_id, threshold_range])\n",
        "        df_metrics.to_csv(os.path.join(self.metric_dir, f'd{distance:02}-{self.file_prefix}-e{self.epoch:03}.csv'))\n",
        "        print('file saved at', os.path.join(self.metric_dir, f'd{distance:02}-{self.file_prefix}-e{self.epoch:03}.csv'))\n",
        "\n",
        "    def _plot(self, datatype, thresholds, recalls, precisions, fscores, kappas, accuracies, distance):\n",
        "        classes = self.cfg.classes\n",
        "        data_dict = {'thresholds': thresholds, 'recalls': recalls, 'precisions': precisions, 'fscores': fscores, 'kappas': kappas, 'accuracies': accuracies}\n",
        "        path_csv = os.path.join(self.plot_dir, f'd{distance:02}-{self.file_prefix}-{datatype}-e{self.epoch:03}.csv')\n",
        "        path_jpg = os.path.join(self.plot_dir, f'd{distance:02}-{self.file_prefix}-{datatype}-e{self.epoch:03}.jpg')\n",
        "        print('[data_dict]\\n', data_dict)\n",
        "        df = pd.DataFrame({'thresholds': thresholds.tolist(), \n",
        "                            'recalls': recalls.flatten().tolist(), \n",
        "                            'precisions': precisions.flatten().tolist(), \n",
        "                            'fscores': fscores.flatten().tolist(), \n",
        "                            'kappas': kappas.flatten().tolist(), \n",
        "                            'accuracies': accuracies.flatten().tolist()})\n",
        "        df.to_csv(path_csv)\n",
        "        plots_data = [['thresholds', 'recalls'], \n",
        "                      ['thresholds', 'precisions'], \n",
        "                      ['thresholds', 'fscores'], \n",
        "                      ['thresholds', 'kappas'], \n",
        "                      ['thresholds', 'accuracies'], \n",
        "                      ['recalls', 'precisions']]\n",
        "        plt.figure(figsize=(21, 14))\n",
        "        for i, plot_data in enumerate(plots_data):\n",
        "            ax = plt.subplot(2, 3, i + 1)\n",
        "            for class_id, class_label in enumerate(classes):\n",
        "                if plot_data[0] == 'thresholds':\n",
        "                    x_data = data_dict[plot_data[0]]\n",
        "                else:\n",
        "                    x_data = data_dict[plot_data[0]][class_id]\n",
        "                y_data = data_dict[plot_data[1]][class_id]\n",
        "                plt.plot(x_data, y_data, label=class_label)\n",
        "            ax.title.set_text(f'{plot_data[0]} vs {plot_data[1]}')\n",
        "            ax.set_xlabel(plot_data[0])\n",
        "            ax.set_ylabel(plot_data[1])\n",
        "        plt.legend()\n",
        "        plt.savefig(path_jpg, dpi=300)\n",
        "        print('file saved at', path_jpg)\n",
        "        plt.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvTvaeKi5DZ8"
      },
      "source": [
        "### File Version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-fFadx55DZ9"
      },
      "source": [
        "eval_hook_file_data = r\"\"\"import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ml_metrics as metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import mmcv\n",
        "from mmcv import Config\n",
        "from mmcv.runner import HOOKS, Hook\n",
        "from mmdet.apis import single_gpu_test\n",
        "\n",
        "from mmdet.datasets import build_dataloader, build_dataset, replace_ImageToTensor\n",
        "\n",
        "@HOOKS.register_module(name='LymphCountEvalHook', force=True)\n",
        "class LymphCountEvalHook(Hook):\n",
        "    def __init__(self, eval_interval, file_prefix, path_config, base_dir):\n",
        "        self.hook_name = 'LymphCountEvalHook'\n",
        "        self.eval_interval = eval_interval\n",
        "        self.file_prefix = file_prefix\n",
        "        self.cfg = Config.fromfile(path_config)\n",
        "        self.cfg.data.samples_per_gpu = 1\n",
        "        self.cfg.data.workers_per_gpu = 1\n",
        "        self.base_dir = os.path.join(self.cfg.work_dir, base_dir)\n",
        "        self.metric_dir = os.path.join(self.base_dir, 'metrics')\n",
        "        self.statistics = os.path.join(self.base_dir, 'statistics')\n",
        "        self.plot_dir = os.path.join(self.base_dir, 'plots')\n",
        "        mmcv.mkdir_or_exist(self.metric_dir)\n",
        "        mmcv.mkdir_or_exist(self.statistics)\n",
        "        mmcv.mkdir_or_exist(self.plot_dir)\n",
        "        self.dataloader_test = self._build_dataloader(self.cfg.data, self.cfg.data.test)\n",
        "\n",
        "    def _build_dataloader(self, cfg_data, data_type):\n",
        "        if isinstance(data_type, dict):\n",
        "            data_type.test_mode = True\n",
        "        elif isinstance(data_type, list):\n",
        "            for ds_cfg in data_type:\n",
        "                ds_cfg.test_mode = True\n",
        "        if cfg_data.samples_per_gpu > 1:\n",
        "            data_type.pipeline = replace_ImageToTensor(data_type.pipeline)\n",
        "        dataset = build_dataset(data_type)\n",
        "        data_loader = build_dataloader(\n",
        "            dataset,\n",
        "            samples_per_gpu=cfg_data.samples_per_gpu,\n",
        "            workers_per_gpu=cfg_data.workers_per_gpu,\n",
        "            dist=False,\n",
        "            shuffle=False)\n",
        "        return data_loader\n",
        "\n",
        "    def eval_sepcific_epoch(self, model, epoch=0):\n",
        "        self.epoch = epoch\n",
        "        print(f'[{self.hook_name}] epoch={self.epoch}')\n",
        "        self._perform_evaluation(model)\n",
        "\n",
        "    def before_epoch(self, runner):\n",
        "        self.epoch = runner.epoch + 1\n",
        "        print(f'[{self.hook_name}] epoch={self.epoch}')\n",
        "        # if self.epoch == 1:\n",
        "        #     self._perform_evaluation(runner.model)\n",
        "\n",
        "    def after_epoch(self, runner):\n",
        "        self.epoch = runner.epoch + 1\n",
        "        print(f'[{self.hook_name}] epoch={self.epoch}')\n",
        "        if self.epoch % self.eval_interval == 0 or self.epoch == self.cfg.total_epochs:\n",
        "            self._perform_evaluation(runner.model)\n",
        "\n",
        "    def _perform_evaluation(self, model):\n",
        "        outputs_test = single_gpu_test(model, self.dataloader_test, False, False, 0.3)\n",
        "        print()\n",
        "        for d in [0, 12]:\n",
        "            eval_metrics = self._calculate('test', self.dataloader_test.dataset, outputs_test, distance=d)\n",
        "            thresholds_test, recalls_test, precisions_test, fscores_test, kappas_test, accuracies_test = eval_metrics\n",
        "            self._save('test', thresholds_test, recalls_test, precisions_test, fscores_test, kappas_test, accuracies_test, distance=d)\n",
        "            self._plot('test', thresholds_test, recalls_test, precisions_test, fscores_test, kappas_test, accuracies_test, distance=d)\n",
        "\n",
        "    def _calculate(self, datatype, dataset, outputs, distance):\n",
        "        step_size = 0.01\n",
        "        thresholds = np.arange(0.0, 1 + step_size, step_size)\n",
        "        classes = self.cfg.classes\n",
        "        recalls = np.zeros((len(classes), len(thresholds)))\n",
        "        precisions = np.zeros((len(classes), len(thresholds)))\n",
        "        fscores = np.zeros((len(classes), len(thresholds)))\n",
        "        kappas = np.zeros((len(classes), len(thresholds)))\n",
        "        accuracies = np.zeros((len(classes), len(thresholds)))\n",
        "        statistics_thresholds = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "        \n",
        "        columns = ['class_id', 'class_label', 'threshold', 'image_id', 'image_name', 'gt_count', 'dt_count', 'TP', 'FP', 'FN', 'distance']\n",
        "        image_statistics = {key: [] for key in columns}\n",
        "        for class_id, class_label in enumerate(classes):\n",
        "            print(f'[{self.hook_name}] d={distance}, class_id={class_id}, class_label={class_label}')\n",
        "            for threshold_index, threshold in enumerate(mmcv.track_iter_progress(thresholds)):\n",
        "                confusion_matrix = np.array([[0, 0], [0, 0]])\n",
        "                kappa_gt_counts, kappa_dt_counts = [], []\n",
        "                for i, idx in enumerate(dataset.img_ids):\n",
        "                    image_id = dataset.img_ids[idx]\n",
        "                    image_name = dataset.data_infos[image_id]['filename']\n",
        "                    gt_count = len(dataset.get_ann_info(image_id)['bboxes'])\n",
        "                    kappa_gt_counts.append(gt_count)\n",
        "                    output = outputs[idx][0]\n",
        "                    scores = output[class_id][:, 4]\n",
        "                    bboxes = output[class_id][:, :4]\n",
        "                    bboxes = bboxes[np.where(scores > threshold)[0]]\n",
        "                    dt_count1 = int(len(bboxes))\n",
        "\n",
        "                    centroid_x = (bboxes[:, 0] + bboxes[:, 2]) / 2\n",
        "                    centroid_y = (bboxes[:, 1] + bboxes[:, 3]) / 2\n",
        "                    merged = []\n",
        "                    if distance > 0:\n",
        "                        for j in range(0, dt_count1 - 1):\n",
        "                            if j not in merged:\n",
        "                                for k in range(j + 1, dt_count1):\n",
        "                                    _distance = int(np.sqrt(np.square(centroid_x[j] - centroid_x[k]) + np.square(centroid_y[j] - centroid_y[k])))\n",
        "                                    if _distance <= distance:\n",
        "                                        merged.append(k)\n",
        "\n",
        "                    dt_count2 = dt_count1 - len(merged)\n",
        "                    kappa_dt_counts.append(dt_count2)\n",
        "                    image_TP, image_FP, image_FN = 0, 0, 0\n",
        "                    if gt_count == dt_count2:\n",
        "                        image_TP = gt_count\n",
        "                    elif gt_count > dt_count2:\n",
        "                        image_TP = dt_count2\n",
        "                        image_FN = np.abs(gt_count - dt_count2)\n",
        "                    elif gt_count < dt_count2:\n",
        "                        image_TP = gt_count\n",
        "                        image_FP = np.abs(gt_count - dt_count2)\n",
        "\n",
        "                    confusion_matrix[0][0] += image_TP\n",
        "                    confusion_matrix[0][1] += image_FP\n",
        "                    confusion_matrix[1][0] += image_FN\n",
        "                    \n",
        "                    if threshold in statistics_thresholds:\n",
        "                        image_statistics['class_id'].append(class_id)\n",
        "                        image_statistics['class_label'].append(class_label)\n",
        "                        image_statistics['threshold'].append(threshold)\n",
        "                        image_statistics['image_id'].append(image_id)\n",
        "                        image_statistics['image_name'].append(image_name)\n",
        "                        image_statistics['gt_count'].append(gt_count)\n",
        "                        image_statistics['dt_count'].append(dt_count2)\n",
        "                        image_statistics['TP'].append(image_TP)\n",
        "                        image_statistics['FP'].append(image_FP)\n",
        "                        image_statistics['FN'].append(image_FN)\n",
        "                        image_statistics['distance'].append(distance)\n",
        "\n",
        "                TP = confusion_matrix[0][0]\n",
        "                FP = confusion_matrix[0][1]\n",
        "                FN = confusion_matrix[1][0]\n",
        "\n",
        "                recall = TP / (TP + FN)\n",
        "                precision = TP / (TP + FP)\n",
        "                precision = precision if not np.isnan(precision) else 1\n",
        "                fscore = 2 * precision * recall / (precision + recall)\n",
        "                kappa = metrics.quadratic_weighted_kappa(kappa_gt_counts, kappa_dt_counts)\n",
        "                accuracy = TP / (TP + FP + FN)\n",
        "\n",
        "                recalls[class_id][threshold_index] = recall\n",
        "                precisions[class_id][threshold_index] = precision\n",
        "                fscores[class_id][threshold_index] = fscore\n",
        "                kappas[class_id][threshold_index] = kappa\n",
        "                accuracies[class_id][threshold_index] = accuracy\n",
        "            print()\n",
        "\n",
        "        df_statistics = pd.DataFrame(image_statistics, columns=columns)\n",
        "        df_statistics.to_csv(os.path.join(self.statistics, f'd{distance:02}-{self.file_prefix}-{datatype}-e{self.epoch:03}.csv'))\n",
        "        return thresholds, np.array(recalls), np.array(precisions), np.array(fscores), np.array(kappas), np.array(accuracies)\n",
        "\n",
        "    def _save(self, datatype, thresholds, recalls, precisions, fscores, kappas, accuracies, distance):\n",
        "        classes = self.cfg.classes\n",
        "        coco_thresholds = {'threshold=0.5:0.95': np.arange(50, 96), 'threshold=0.25': 25, 'threshold=0.50': 50, 'threshold=0.75': 75, 'threshold=0.95': 95, 'threshold-max_fscore': -1}\n",
        "        columns = ['class_label', 'threshold', 'recall', 'precision', 'fscore', 'kappa', 'accuracy']\n",
        "        df_metrics = pd.DataFrame(index=range(len(classes) * len(coco_thresholds.keys())), columns=columns, dtype=np.float32)\n",
        "        df_metrics = df_metrics.fillna(0)\n",
        "        for class_id, class_label in enumerate(classes):\n",
        "            for threshold_idx, threshold in enumerate(coco_thresholds):\n",
        "                idx = int(class_id * len(coco_thresholds.keys()) + threshold_idx)\n",
        "                threshold_range = coco_thresholds[threshold]\n",
        "                if threshold == 'threshold-max_fscore':\n",
        "                    threshold_range = np.argmax(fscores[class_id])\n",
        "                df_metrics.loc[idx, columns[0]] = class_label\n",
        "                df_metrics.loc[idx, columns[1]] = threshold\n",
        "                df_metrics.loc[idx, columns[2]] = np.average(recalls[class_id, threshold_range])\n",
        "                df_metrics.loc[idx, columns[3]] = np.average(precisions[class_id, threshold_range])\n",
        "                df_metrics.loc[idx, columns[4]] = np.average(fscores[class_id, threshold_range])\n",
        "                df_metrics.loc[idx, columns[5]] = np.average(kappas[class_id, threshold_range])\n",
        "                df_metrics.loc[idx, columns[6]] = np.average(accuracies[class_id, threshold_range])\n",
        "        df_metrics.to_csv(os.path.join(self.metric_dir, f'd{distance:02}-{self.file_prefix}-e{self.epoch:03}.csv'))\n",
        "        print('file saved at', os.path.join(self.metric_dir, f'd{distance:02}-{self.file_prefix}-e{self.epoch:03}.csv'))\n",
        "\n",
        "    def _plot(self, datatype, thresholds, recalls, precisions, fscores, kappas, accuracies, distance):\n",
        "        classes = self.cfg.classes\n",
        "        data_dict = {'thresholds': thresholds, 'recalls': recalls, 'precisions': precisions, 'fscores': fscores, 'kappas': kappas, 'accuracies': accuracies}\n",
        "        path_csv = os.path.join(self.plot_dir, f'd{distance:02}-{self.file_prefix}-{datatype}-e{self.epoch:03}.csv')\n",
        "        path_jpg = os.path.join(self.plot_dir, f'd{distance:02}-{self.file_prefix}-{datatype}-e{self.epoch:03}.jpg')\n",
        "        print('[data_dict]\\n', data_dict)\n",
        "        df = pd.DataFrame({'thresholds': thresholds.tolist(), \n",
        "                            'recalls': recalls.flatten().tolist(), \n",
        "                            'precisions': precisions.flatten().tolist(), \n",
        "                            'fscores': fscores.flatten().tolist(), \n",
        "                            'kappas': kappas.flatten().tolist(), \n",
        "                            'accuracies': accuracies.flatten().tolist()})\n",
        "        df.to_csv(path_csv)\n",
        "        plots_data = [['thresholds', 'recalls'], \n",
        "                      ['thresholds', 'precisions'], \n",
        "                      ['thresholds', 'fscores'], \n",
        "                      ['thresholds', 'kappas'], \n",
        "                      ['thresholds', 'accuracies'], \n",
        "                      ['recalls', 'precisions']]\n",
        "        plt.figure(figsize=(21, 14))\n",
        "        for i, plot_data in enumerate(plots_data):\n",
        "            ax = plt.subplot(2, 3, i + 1)\n",
        "            for class_id, class_label in enumerate(classes):\n",
        "                if plot_data[0] == 'thresholds':\n",
        "                    x_data = data_dict[plot_data[0]]\n",
        "                else:\n",
        "                    x_data = data_dict[plot_data[0]][class_id]\n",
        "                y_data = data_dict[plot_data[1]][class_id]\n",
        "                plt.plot(x_data, y_data, label=class_label)\n",
        "            ax.title.set_text(f'{plot_data[0]} vs {plot_data[1]}')\n",
        "            ax.set_xlabel(plot_data[0])\n",
        "            ax.set_ylabel(plot_data[1])\n",
        "        plt.legend()\n",
        "        plt.savefig(path_jpg, dpi=300)\n",
        "        print('file saved at', path_jpg)\n",
        "        plt.close()\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "eval_hook_base_path = 'mmdet/core/utils/'\n",
        "eval_hook_file_name = 'lymph_count_eval_hook.py'\n",
        "eval_hook_file_path = os.path.join(eval_hook_base_path, eval_hook_file_name)\n",
        "with open(eval_hook_file_path, 'w') as eval_hook_file:\n",
        "    eval_hook_file.write(eval_hook_file_data)\n",
        "    print(f'<eval_hook_file_data> saved to \"{eval_hook_file_path}\"')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tWVer2xCV6-"
      },
      "source": [
        "# Define Custom Config\n",
        "Save the custom config inside the folder \"configs/lymph/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfYDELpvo45Z"
      },
      "source": [
        "Check items in work_dir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDdvg6iNdLMF"
      },
      "source": [
        "!ls '/content/drive/MyDrive/0-FYP/codes/mmdetection-stuff/work_dir_maskrcnn_lymphocytenet3_CM1/setting4' -l1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lW1SimAUQVk"
      },
      "source": [
        "## 4: DAB images + LymphocyteNet3_CM1 + FPN + 30 epochs + 0.0025LR + Step Scheduler [10, 18, 25] + SGD NESTROV + New Anchor Configurations\n",
        "\n",
        "Anchor Scale: [2, 4]\n",
        "\n",
        "Ancohr Ratio: [0.2, 0.5, 1.0, 2.0, 5.0]\n",
        "\n",
        "Anchor Stride: [4, 8, 16, 32, 64]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it7iEQw10Brv"
      },
      "source": [
        "Print the base config file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWnlcts4Q7W5"
      },
      "source": [
        "# !python \"/content/mmdetection/tools/misc/print_config.py\" \"/content/mmdetection/configs/lymph/mask_rcnn_r50_fpn_2x_lymphocyte4.py\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLHy8BTvUQWI"
      },
      "source": [
        "# create config folder if not already created\n",
        "setting4 = 4\n",
        "config_base_path4 = 'configs/lymph/'\n",
        "mmcv.mkdir_or_exist(os.path.abspath(config_base_path4))\n",
        "\n",
        "# create config file and store config data declared above\n",
        "config_file_name4 = f'mask_rcnn_r50_fpn_2x_lymphocyte{setting4}.py'\n",
        "config_file_path4 = os.path.join(config_base_path4, config_file_name4)\n",
        "\n",
        "# lymph config file content\n",
        "config_file_data4 = f\"\"\"# The new config inherits a base config to highlight the necessary modification\n",
        "_base_ = '../mask_rcnn/mask_rcnn_r50_fpn_2x_coco.py'\n",
        "\n",
        "# We also need to change the num_classes in head to match the dataset's annotation\n",
        "model = dict(\n",
        "    pretrained='torchvision://resnet50;open-mmlab://resnext50_32x4d',\n",
        "    backbone=dict(\n",
        "        _delete_=True,\n",
        "        type='LymphocyteNet3_CM1',\n",
        "        debug=False),\n",
        "    rpn_head=dict(\n",
        "        type='RPNHead',\n",
        "        anchor_generator=dict(\n",
        "            type='AnchorGenerator',\n",
        "            scales=[2, 4],\n",
        "            ratios=[0.2, 0.5, 1.0, 2.0, 5.0],\n",
        "            strides=[4, 8, 16, 32, 64])),\n",
        "    roi_head=dict(\n",
        "        bbox_head=dict(num_classes=1),\n",
        "        mask_head=dict(num_classes=1)))\n",
        "\n",
        "custom_imports = dict(\n",
        "    imports=[\n",
        "        'mmdet.models.backbones.resnet_cbam',\n",
        "        'mmdet.models.backbones.lymphocytenet3_CM1',\n",
        "        'mmdet.core.utils.lymph_count_eval_hook',\n",
        "    ],\n",
        "    allow_failed_imports=False)\n",
        "\n",
        "# Modify dataset related settings\n",
        "dataset_type = 'COCODataset'\n",
        "classes = ('lymphocyte',)\n",
        "data = dict(\n",
        "    samples_per_gpu=4,\n",
        "    workers_per_gpu=4,\n",
        "    train=dict(\n",
        "        img_prefix='./{PATH_DATASET}/train_DAB_images/',\n",
        "        classes=classes,\n",
        "        ann_file='./{PATH_DATASET}/train_annotations.json',\n",
        "        pipeline=[\n",
        "            dict(type='LoadImageFromFile'),\n",
        "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
        "            dict(type='Resize', img_scale=(224, 224), keep_ratio=True),\n",
        "            dict(type='RandomFlip', flip_ratio=0.5),\n",
        "            dict(\n",
        "                type='Normalize',\n",
        "                mean=[123.675, 116.28, 103.53],\n",
        "                std=[58.395, 57.12, 57.375],\n",
        "                to_rgb=True),\n",
        "            dict(type='Pad', size_divisor=32),\n",
        "            dict(type='DefaultFormatBundle'),\n",
        "            dict(\n",
        "                type='Collect',\n",
        "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
        "        ]),\n",
        "    val=dict(\n",
        "        img_prefix='./{PATH_DATASET}/val_DAB_images/',\n",
        "        classes=classes,\n",
        "        ann_file='./{PATH_DATASET}/val_annotations.json',\n",
        "        pipeline=[\n",
        "            dict(type='LoadImageFromFile'),\n",
        "            dict(\n",
        "                type='MultiScaleFlipAug',\n",
        "                img_scale=(224, 224),\n",
        "                flip=False,\n",
        "                transforms=[\n",
        "                    dict(type='Resize', keep_ratio=True),\n",
        "                    dict(type='RandomFlip'),\n",
        "                    dict(\n",
        "                        type='Normalize',\n",
        "                        mean=[123.675, 116.28, 103.53],\n",
        "                        std=[58.395, 57.12, 57.375],\n",
        "                        to_rgb=True),\n",
        "                    dict(type='Pad', size_divisor=32),\n",
        "                    dict(type='ImageToTensor', keys=['img']),\n",
        "                    dict(type='Collect', keys=['img'])\n",
        "                ])\n",
        "        ]),\n",
        "    test=dict(\n",
        "        img_prefix='./{PATH_DATASET}/test_DAB_images1/',\n",
        "        classes=classes,\n",
        "        ann_file='./{PATH_DATASET}/test_annotations.json',\n",
        "        pipeline=[\n",
        "            dict(type='LoadImageFromFile'),\n",
        "            dict(\n",
        "                type='MultiScaleFlipAug',\n",
        "                img_scale=(224, 224),\n",
        "                flip=False,\n",
        "                transforms=[\n",
        "                    dict(type='Resize', keep_ratio=True),\n",
        "                    dict(type='RandomFlip'),\n",
        "                    dict(\n",
        "                        type='Normalize',\n",
        "                        mean=[123.675, 116.28, 103.53],\n",
        "                        std=[58.395, 57.12, 57.375],\n",
        "                        to_rgb=True),\n",
        "                    dict(type='Pad', size_divisor=32),\n",
        "                    dict(type='ImageToTensor', keys=['img']),\n",
        "                    dict(type='Collect', keys=['img'])\n",
        "                ])\n",
        "        ]))\n",
        "\n",
        "custom_hooks = [\n",
        "    # dict(\n",
        "    #     type='LymphCountEvalHook',\n",
        "    #     eval_interval=4,\n",
        "    #     file_prefix='maskrcnn-lymphocytenet3-CM-s4',\n",
        "    #     path_config='{config_file_path4}',\n",
        "    #     base_dir='evaluation1')\n",
        "    dict(\n",
        "        type='LymphCountEvalHook', \n",
        "        path_config='{config_file_path4}', \n",
        "        base_dir='evaluation1')\n",
        "]\n",
        "\n",
        "# setting4\n",
        "lr_config = dict(\n",
        "    policy='step',\n",
        "    warmup='linear',\n",
        "    warmup_iters=500,\n",
        "    warmup_ratio=0.0025,\n",
        "    step=[10, 18, 25])\n",
        "\n",
        "work_dir = '{os.path.join(WORK_DIR1, 'setting' + setting4)}'\n",
        "load_from = 'checkpoints/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-0.392__segm_mAP-0.354_20200505_003907-3e542a40.pth'\n",
        "# load_from = '{os.path.join(WORK_DIR1, 'setting' + setting4, 'epoch_30.pth')}'\n",
        "# resume_from = '{os.path.join(WORK_DIR1, 'setting' + setting4, 'latest.pth')}'\n",
        "\n",
        "total_epochs = 30\n",
        "runner = dict(type='EpochBasedRunner', max_epochs=total_epochs)\n",
        "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
        "evaluation = dict(metric=['bbox', 'segm'], interval=100)\n",
        "checkpoint_config = dict(interval=4)\n",
        "log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\n",
        "seed = 0\n",
        "gpu_ids = range(1)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(config_file_path4, 'w') as config_file:\n",
        "    config_file.write(config_file_data4)\n",
        "    print(f'<config_file_data4> saved to \"{config_file_path4}\"')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7C5-puTqXQS"
      },
      "source": [
        "# Training\n",
        "\n",
        "Create Config object and print the configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B5x3frO1Kf6"
      },
      "source": [
        "set_random_seed(0, deterministic=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ4npaXqW_z4"
      },
      "source": [
        "cfg4 = Config.fromfile(config_file_path4)\n",
        "print(f'Config:\\n{cfg4.pretty_text}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G03YEJ2ZoYR_"
      },
      "source": [
        "Run these lines to deal with \"GPU out of memory\", this cell clears GPU cache"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKLx4-r0BHUG"
      },
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrHzyH4oqQrp"
      },
      "source": [
        "Create dataset and model objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOhXbrmmXFUu"
      },
      "source": [
        "# Build dataset\n",
        "datasets4 = [build_dataset(cfg4.data.train)]\n",
        "\n",
        "# Build the detector\n",
        "model4 = build_detector(cfg4.model)\n",
        "model4.cfg = cfg4\n",
        "\n",
        "# Add an attribute for visualization convenience\n",
        "model4.CLASSES = datasets4[0].CLASSES\n",
        "\n",
        "# craete working directory to store logs and model4 checkpoints\n",
        "mmcv.mkdir_or_exist(cfg4.work_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FP2H_zaXFUx"
      },
      "source": [
        "train_detector(model4, datasets4, cfg4, distributed=False, validate=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGsJzCQtab5p"
      },
      "source": [
        "Check number of parameters of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTfdqr8IzWtV"
      },
      "source": [
        "import torch\n",
        "from mmcv import Config\n",
        "from mmdet.models import build_detector\n",
        "from mmcv.cnn import get_model_complexity_info\n",
        "\n",
        "def main_get_flops(config, input_shape):\n",
        "    TAG = '[main_get_flops]'\n",
        "    print(TAG, '[starts]')\n",
        "\n",
        "    cfg = Config.fromfile(config)\n",
        "    # import modules from string list.\n",
        "    if cfg.get('custom_imports', None):\n",
        "        from mmcv.utils import import_modules_from_strings\n",
        "        import_modules_from_strings(**cfg['custom_imports'])\n",
        "\n",
        "    model = build_detector(cfg.model)\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "    model.eval()\n",
        "\n",
        "    if hasattr(model, 'forward_dummy'):\n",
        "        model.forward = model.forward_dummy\n",
        "    else:\n",
        "        raise NotImplementedError('FLOPs counter is currently not currently supported with {}'.format(model.__class__.__name__))\n",
        "\n",
        "    flops, params = get_model_complexity_info(model, input_shape)\n",
        "    split_line = '=' * 30\n",
        "    print()\n",
        "    print(f'{split_line}\\nInput shape: {input_shape}\\n'\n",
        "          f'Flops: {flops}\\nParams: {params}\\n{split_line}')\n",
        "    print('!!!Please be cautious if you use the results in papers. '\n",
        "          'You may need to check if all ops are supported and verify that the '\n",
        "          'flops computation is correct.')\n",
        "    print(TAG, '[ends]')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opO9JIE37O-l"
      },
      "source": [
        "main_get_flops(config_file_path4, (3, 224, 224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRSHtpbGqgzh"
      },
      "source": [
        "# Testing\n",
        "\n",
        "Testing to obtain mAPs for test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS9Trq0euQvr"
      },
      "source": [
        "!python tools/test.py 'configs/lymph/mask_rcnn_r50_fpn_2x_lymphocyte.py' '/content/drive/MyDrive/abdul-rehman-khan/0-FYP/codes/mmdetection-stuff/work_dir_maskrcnn_lymphocytenet3_cm1/setting4/latest.pth' --eval bbox segm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnzv4lofquuq"
      },
      "source": [
        "Generate and save plots using Training Logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlR2DVDniMqP"
      },
      "source": [
        "!python tools/analysis_tools/analyze_logs.py plot_curve \"/content/drive/MyDrive/abdul-rehman-khan/0-FYP/codes/mmdetection-stuff/work_dir_maskrcnn_lymphocytenet3_cm1/setting4/None.log.json\" --keys loss_cls --title \"Mask RCNN with ResNet-50 | Lysto | Loss Cls\" --legend \"loss_cls\" --out \"maskrcnn-resnet50-lysto-loss_cls-e10.jpg\"\n",
        "!python tools/analysis_tools/analyze_logs.py plot_curve \"/content/drive/MyDrive/abdul-rehman-khan/0-FYP/codes/mmdetection-stuff/work_dir_maskrcnn_lymphocytenet3_cm1/setting4/None.log.json\" --keys loss_bbox --title \"Mask RCNN with ResNet-50 | Lysto | Loss BBox\" --legend \"loss_bbox\" --out \"maskrcnn-resnet50-lysto-loss_bbox-e10.jpg\"\n",
        "!python tools/analysis_tools/analyze_logs.py plot_curve \"/content/drive/MyDrive/abdul-rehman-khan/0-FYP/codes/mmdetection-stuff/work_dir_maskrcnn_lymphocytenet3_cm1/setting4/None.log.json\" --keys loss_mask --title \"Mask RCNN with ResNet-50 | Lysto | Loss Mask\" --legend \"loss_mask\" --out \"maskrcnn-resnet50-lysto-loss_mask-e10.jpg\"\n",
        "!python tools/analysis_tools/analyze_logs.py plot_curve \"/content/drive/MyDrive/abdul-rehman-khan/0-FYP/codes/mmdetection-stuff/work_dir_maskrcnn_lymphocytenet3_cm1/setting4/None.log.json\" --keys acc --title \"Mask RCNN with ResNet-50 | Lysto | Accuracy\" --legend \"accuracy\" --out \"maskrcnn-resnet50-lysto-accuracy-e10.jpg\"\n",
        "!python tools/analysis_tools/analyze_logs.py plot_curve \"/content/drive/MyDrive/abdul-rehman-khan/0-FYP/codes/mmdetection-stuff/work_dir_maskrcnn_lymphocytenet3_cm1/setting4/None.log.json\" --keys bbox_mAP segm_mAP --title \"Mask RCNN with ResNet-50 | Lysto | mAPs\" --legend \"bbox_mAP\" \"segm_mAP\" --out \"maskrcnn-resnet50-lysto-mAP-e10.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OT0u1aXJgaP"
      },
      "source": [
        "# Get output images using the trained model on Test/Validation Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZN8i76e1scB"
      },
      "source": [
        "def draw_annotations_from_result(image, result, model_name, score_thr=0.3, overlay_factor=0.5, draw_bboxes=True, draw_masks=True, stroke_weight=1):\n",
        "    image_output = cv2.cvtColor(image.copy(), cv2.COLOR_RGB2BGR)\n",
        "    image_mask = np.zeros(image.shape[:2])\n",
        "\n",
        "    idx = np.where(result[0][0][:, 4] > score_thr)\n",
        "    # print('idx ->', idx)\n",
        "\n",
        "    if len(idx[0]) != 0:\n",
        "        if model_name == 'maskrcnn':\n",
        "            bboxes, masks = np.array(result[0][0]), np.array(result[1][0])\n",
        "        elif model_name == 'msrcnn':\n",
        "            bboxes, masks = np.array(result[0][0]), np.array(result[1][0][0])\n",
        "        bboxes, masks = bboxes[idx], masks[idx]\n",
        "\n",
        "        # draw bounding boxes\n",
        "        if draw_bboxes:\n",
        "            for bbox in bboxes:\n",
        "                bb_x1 = int(bbox[0])\n",
        "                bb_y1 = int(bbox[1])\n",
        "                bb_w  = int(bbox[2] - bbox[0])\n",
        "                bb_h  = int(bbox[3] - bbox[1])\n",
        "                cv2.rectangle(image_output, [bb_x1, bb_y1, bb_w, bb_h], (255, 0, 0), stroke_weight)\n",
        "        \n",
        "        # draw masks\n",
        "        if draw_masks:\n",
        "            for index, mask in enumerate(masks):\n",
        "                image_mask = np.logical_or(image_mask, mask)\n",
        "\n",
        "            overlay = np.ones(image.shape, dtype=np.uint8)\n",
        "            overlay[:, :, 0] *= 255\n",
        "            overlay[:, :, 1] *= 0\n",
        "            overlay[:, :, 2] *= 255\n",
        "\n",
        "            # image_output_mask > 0 represents mask regions, get index for those pixels\n",
        "            mask_indices = np.where(image_mask > 0)\n",
        "            if overlay_factor > 1 or overlay_factor < 0: overlay_factor = 0.5\n",
        "            # print(type(image_output), type(image_output[mask_indices]), type(mask_indices), type(overlay), type(overlay[mask_indices]))\n",
        "            # print(len(image_output), len(image_output[mask_indices]), len(mask_indices), len(overlay), len(overlay[mask_indices]))\n",
        "            image_output[mask_indices] = cv2.addWeighted(image_output[mask_indices], 1 - overlay_factor, overlay[mask_indices], overlay_factor, 0)\n",
        "        \n",
        "    image_mask = np.stack([image_mask, image_mask, image_mask], axis=2).astype(np.uint8) * 255\n",
        "    image_mask = cv2.cvtColor(image_mask, cv2.COLOR_BGR2RGB)\n",
        "    image_output = cv2.cvtColor(image_output, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    return image_output, image_mask\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLqE70YiFNxo"
      },
      "source": [
        "cfg.load_from = os.path.join(cfg.work_dir, 'latest.pth')\n",
        "dataset = build_dataset(cfg.data.test)\n",
        "model = init_detector(cfg, cfg.load_from, device='cpu')\n",
        "model.CLASSES = dataset.CLASSES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F-9Va3dFYmC"
      },
      "source": [
        "image_names = []\n",
        "results = []\n",
        "\n",
        "X0, N, S = 0, 10, 100\n",
        "for i, idx in enumerate(range(X0, X0 + N * S, S)):\n",
        "    if idx < len(dataset.img_ids):\n",
        "        image_id = dataset.img_ids[idx]\n",
        "        image_name = dataset.data_infos[image_id]['filename']\n",
        "        print(f'i={i}, idx={idx}, image_id={image_id}, image_name={image_name}')\n",
        "        image_names.append(image_name)\n",
        "\n",
        "        img_original = mmcv.imread(os.path.join(dataset.img_prefix, image_name))\n",
        "        result = inference_detector(model, img_original)\n",
        "        results.append(result)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwfC0AWeFbfF"
      },
      "source": [
        "plt.figure(figsize=(20, 100))\n",
        "\n",
        "for j in range(0, 100):\n",
        "    threshold = j / 100\n",
        "    plt_images = []\n",
        "    for i in range(len(image_names)):\n",
        "        image_name = image_names[i]\n",
        "        result = results[i]\n",
        "        img_original = mmcv.imread(os.path.join(dataset.img_prefix, image_name))\n",
        "        img_annotation = mmcv.imread(os.path.join('lymphocyte_dataset/test_mask_images/', image_name))\n",
        "        image_with_mask, mask_image = draw_annotations_from_result(img_original, result, model_name='msrcnn', score_thr=threshold, overlay_factor=0.5, stroke_weight=1)\n",
        "        row = np.concatenate([img_original, img_annotation, np.ones((256, 1, 3), dtype=np.int8) * 255, mask_image, image_with_mask], axis=1)\n",
        "        plt_images.append(row)\n",
        "    output_image = np.concatenate(plt_images, axis=0).astype(np.uint8)\n",
        "    plt.imshow(output_image)\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "    plt.tight_layout(pad=0)\n",
        "    plt.imsave(f'outputs/output_thr{j}.jpg', output_image, dpi=300)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZnqqKT2fDZ7"
      },
      "source": [
        "!zip -r \"outputs.zip\" \"outputs/\" &> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC-HKZPkvCh0"
      },
      "source": [
        "# LYSTO Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuCwlP2csdnC"
      },
      "source": [
        "Evaluate Specific Epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJioH_d9y0SG"
      },
      "source": [
        "path_config = 'configs/lymph/mask_rcnn_r50_fpn_2x_lymphocyte4.py'\n",
        "cfg = Config.fromfile(path_config)\n",
        "\n",
        "epoch = 30\n",
        "cfg.load_from = os.path.join(cfg.work_dir, f'epoch_{epoch}_final.pth')\n",
        "print(cfg.load_from)\n",
        "cfg.resume_from = ''\n",
        "cfg.data.samples_per_gpu = 1\n",
        "cfg.data.workers_per_gpu = 1\n",
        "\n",
        "dataset = build_dataset(cfg.data.test)\n",
        "\n",
        "print(cfg.load_from)\n",
        "model = init_detector(cfg, cfg.load_from)\n",
        "model.CLASSES = dataset.CLASSES\n",
        "model = MMDataParallel(model, device_ids=[0])\n",
        "model.eval()\n",
        "\n",
        "evaluator_cfg = cfg.custom_hooks[0]\n",
        "evaluator = LymphCountEvalHook(evaluator_cfg.eval_interval, evaluator_cfg.file_prefix, evaluator_cfg.path_config, evaluator_cfg.base_dir)\n",
        "# evaluator = LymphCountEvalHook(evaluator_cfg.path_config, evaluator_cfg.base_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuKTicJGeJhs"
      },
      "source": [
        "evaluator.eval_sepcific_epoch(model, epoch=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRP5DJbPKa1p"
      },
      "source": [
        "# Below code draws ground truth annotations on corrosponding dataset images to verify annotation correctness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i-yGBm_cToQ"
      },
      "source": [
        "def draw_annotations_from_mask(image_id, dataset, draw_bboxes=True, draw_masks=True, stroke_weight=1):\n",
        "    # create file name from image_id\n",
        "    image_filename = os.path.join(dataset.img_prefix, dataset.data_infos[image_id]['filename'])\n",
        "    # open image\n",
        "    original_img = mmcv.imread(image_filename)\n",
        "    # annotations will be drawn on img\n",
        "    img = original_img.copy()\n",
        "    # extract only bounding boxes and masks data for required image\n",
        "    bboxes = dataset.get_ann_info(image_id)['bboxes']\n",
        "    masks = dataset.get_ann_info(image_id)['masks']\n",
        "\n",
        "    # draw bounding boxes\n",
        "    if draw_bboxes:\n",
        "        for bbox in bboxes:\n",
        "            bb_x1 = int(bbox[0])\n",
        "            bb_y1 = int(bbox[1])\n",
        "            bb_w  = int(bbox[2] - bbox[0])\n",
        "            bb_h  = int(bbox[3] - bbox[1])\n",
        "            cv2.rectangle(img, [bb_x1, bb_y1, bb_w, bb_h], (255, 0, 0), stroke_weight)\n",
        "\n",
        "    # draw masks\n",
        "    if draw_masks:\n",
        "        polygon_masks = []\n",
        "        for index, mask in enumerate(masks):\n",
        "            polygon_masks.append(np.array(mask, np.int32).reshape(-1, 1, 2))\n",
        "\n",
        "        img_mask = np.zeros_like(img)\n",
        "        # draw white filled regions to represent actual mask in image\n",
        "        cv2.fillPoly(img_mask, polygon_masks, (255,255,255), cv2.LINE_AA)\n",
        "        # convert image from bgr to gray then convert back to bgr, to get grayscale image with 3 channel\n",
        "        final_image = cv2.cvtColor(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), cv2.COLOR_GRAY2BGR)\n",
        "        # img_mask > 0 represents mask regions, get index for those pixels\n",
        "        mask_indices = np.where(img_mask > 0)\n",
        "        # to show only masked regions as colorful\n",
        "        # replace regions on final_image (grayscale image) with regions from img (color image)\n",
        "        final_image[mask_indices] = img[mask_indices]\n",
        "\n",
        "    return cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB), final_image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQcP2kfbcy5t"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# build dataset to draw ground truth annotation\n",
        "dataset = build_dataset(cfg.data.val)\n",
        "\n",
        "# target = ['04_02_1', '06_55_1', '65_01_10']\n",
        "\n",
        "# in case of error image will be black\n",
        "large_image = np.zeros((512, 512))\n",
        "\n",
        "# draw annotations for 10 images only\n",
        "for i in range(1):\n",
        "    image_id = dataset.img_ids[i]\n",
        "    image_name = dataset.data_infos[image_id]['filename']\n",
        "    print(image_name)\n",
        "    original_image, annotated_image = draw_annotations(image_id, dataset, stroke_weight=2)\n",
        "\n",
        "    combined_image = np.concatenate([original_image, annotated_image], axis=1)\n",
        "    # if i == 0:\n",
        "    #     large_image = combined_image\n",
        "    # else:\n",
        "    #     large_image = np.concatenate([large_image, combined_image], axis=0)\n",
        "    # plt.imsave(f'{image_name}', annotated_image)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(annotated_image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HBkfMKwRuPW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}